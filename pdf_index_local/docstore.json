{"docstore/data": {"cbb491e7-f536-4bb4-a240-c027ed4f8ae5": {"__data__": {"id_": "cbb491e7-f536-4bb4-a240-c027ed4f8ae5", "embedding": null, "metadata": {"page_label": "1", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "00f122b5-dc86-43d0-8623-8fe1a1cf64c7", "node_type": "4", "metadata": {"page_label": "1", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "hash": "979ea515337490d25a9b68e94d258a97048c56dd76e9eb86e1ff1674354ba361", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e4677d8d-df79-4644-8ea6-a6d01e42e2cf", "node_type": "1", "metadata": {}, "hash": "adf8c66c1b8684cdf1400105a9277735305eb652f811f6125e64a203dcff8cc8", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "STANDARDIZE : Aligning Language Models with Expert-Defined Standards\nfor Content Generation\nJoseph Marvin Imperial\u2126,\u039b Gail Forey\u039b Harish Tayyar Madabushi\u039b\n\u039bUniversity of Bath, UK\n\u2126National University, Philippines\njmri20@bath.ac.uk gf370@bath.ac.uk htm43@bath.ac.uk\nAbstract\nDomain experts across engineering, healthcare,\nand education follow strict standards for pro-\nducing quality content such as technical man-\nuals, medication instructions, and children\u2019s\nreading materials. However, current works in\ncontrollable text generation have yet to explore\nusing these standards as references for control.\nTowards this end, we introduce STANDARD -\nIZE , a retrieval-style in-context learning-based\nframework to guide large language models to\nalign with expert-defined standards. Focusing\non English language standards in the education\ndomain as a use case, we consider the Com-\nmon European Framework of Reference for\nLanguages (CEFR) and Common Core Stan-\ndards (CCS) for the task of open-ended content\ngeneration. Our findings show that models can\ngain 45% to 100% increase in precise accuracy\nacross open and commercial LLMs evaluated,\ndemonstrating that the use of knowledge ar-\ntifacts extracted from standards and integrat-\ning them in the generation process can effec-\ntively guide models to produce better standard-\naligned content.1\n1 Introduction\nOne of the most realized benefits of large language\nmodel (LLM) research is how it became widely\nadopted by the public. In particular, the rise of chat-\nstyle model interfaces, such as ChatGPT and Per-\nplexity, has allowed non-technical users to fully uti-\nlize these tools in accomplishing day-to-day tasks\nand activities, such as getting help with writing,\ndocumenting code, and providing recommenda-\ntions. A key technological advancement behind\nthis is the use of reward-based methods such as Re-\ninforcement Learning for Human Feedback (RLHF,\nOuyang et al. (2022)), which embeds human pref-\nerences to generative models for better-aligned out-\nputs with respect to the task at hand.\n1Code and data: https://github.com/imperia\nlite/standardize-ctg\nSTANDARDIZE Framework (Proposed Method)\n(i) Target Specification \nExtraction\n(ii) Specification \nLookup and Retrieval\n(iii) Knowledge \nAugmentation \nGiven this prompt: In the dark old forest up ahead, \na solitary figure emerged from the corner of the\u2026\nContinue the story and make sure they are readable \nfor B1 learners in the CEFR scale.\nGenerative \nLanguage \nModel\nCommon European \nFramework of Reference \nfor Languages (CEFR)\n\u201cContinue the story and \nmake sure they are \nreadable for B1 learners \nin the CEFR scale. \u201d\n \u201cIn B1 content, texts can \nbe long but not complex \nand observes mostly \nlogical \u2026\nA - Aspect Information\nE - Exemplars\nL - Linguistic Flags\nTeacher Style\nGiven this prompt: In the dark old forest up \nahead, a solitary \ufb01gure emerged from the corner \nof the shadowy grove\u2026\n        \nContinue the story and make sure they are \nreadable for B1 learners in the CEFR scale and \nobserves the following speci\ufb01cations:\n1. Meaning or Purpose: The text is clear and \nconcrete, and tells a simple story.\n2. Structure: The text is can be long but not \ncomplex, and observes mostly chronological \nwith possible \ufb02ashbacks.\n3. Grammatical Complexity: The text may \ncontain future forms, future in the past, repeated \nactions, present perfect simple forms.\nAspect Information \nGiven this prompt: In the dark old forest up \nahead, a solitary \ufb01gure emerged from the corner \nof the shadowy grove\u2026\n        \nContinue the story and make sure they are \nreadable for B1 learners in the CEFR scale. \nExample books in the same level of complexity \ninclude Frankenstein by Mary Shelley, Wuthering \nHeights by Emily Bronte, and Midsummer Night's \nDream by Shakespeare.\nExemplars \nGiven this story: The trees around the \ufb01gure seem \nto close in, branches twisting and writhing..\n        \nRewrite the story and make sure they are \nreadable for B1 learners in the CEFR scale. Use \nthe following linguistic features to reach the \ntarget level of the story:\n1.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4053, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e4677d8d-df79-4644-8ea6-a6d01e42e2cf": {"__data__": {"id_": "e4677d8d-df79-4644-8ea6-a6d01e42e2cf", "embedding": null, "metadata": {"page_label": "1", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "00f122b5-dc86-43d0-8623-8fe1a1cf64c7", "node_type": "4", "metadata": {"page_label": "1", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "hash": "979ea515337490d25a9b68e94d258a97048c56dd76e9eb86e1ff1674354ba361", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "cbb491e7-f536-4bb4-a240-c027ed4f8ae5", "node_type": "1", "metadata": {"page_label": "1", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "hash": "91af2c16cde4e252775770f45b1aaa30d47071f7e159e19d48631831d0a8b118", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "3. Grammatical Complexity: The text may \ncontain future forms, future in the past, repeated \nactions, present perfect simple forms.\nAspect Information \nGiven this prompt: In the dark old forest up \nahead, a solitary \ufb01gure emerged from the corner \nof the shadowy grove\u2026\n        \nContinue the story and make sure they are \nreadable for B1 learners in the CEFR scale. \nExample books in the same level of complexity \ninclude Frankenstein by Mary Shelley, Wuthering \nHeights by Emily Bronte, and Midsummer Night's \nDream by Shakespeare.\nExemplars \nGiven this story: The trees around the \ufb01gure seem \nto close in, branches twisting and writhing..\n        \nRewrite the story and make sure they are \nreadable for B1 learners in the CEFR scale. Use \nthe following linguistic features to reach the \ntarget level of the story:\n1. The type token ratio of the current story is \n4.22 while the mean value in the target level is \nclose to 12.50. Increase the complexity by \naiming for higher type token ratio.\n2. The average number of words of the current \nstory is 510 while the mean value in the target \nlevel is close to 420. Decrease the complexity by \naiming for lower average number of words.\nLinguistic Flags \nGiven this story: In the dark old forest up ahead, a \nsolitary \ufb01gure emerged from the corner of the...\n        \nRewrite the story and make sure they are readable for \nB1 learners in the CEFR scale. Use the following \nlinguistic features to reach the target level of the story:\n1. The type token ratio of the current story is 4.22 while \nthe mean value in the target level is close to 12.50. \nIncrease the complexity by aiming for higher type token \nratio.\n2. The average number of words of the current story is \n510 while the mean value in the target level is close to \n420. Decrease the complexity by aiming for lower \naverage number of words.\nKnowledge Artifact-Enhanced Prompt\nFigure 1: In contrast to the simple prompting method\nused by teachers, the proposed STANDARDIZE frame-\nwork aims to improve the performance of generative\nmodels for content generation by using the fine-grained\ninformation found in expert-defined standards. The\nframework involves a three-part process starting with the\n(i) extraction of target specifications from the prompt,\n(ii) lookup and retrieval of information that matches\nthe target specifications from the specified standard, and\n(iii) knowledge augmentation to produce artifacts that\nrepresent the standard itself for integration into the gen-\neration process with generative models.\nDespite the growing literature of complex\nalgorithms and architectures for enriching the\ninstruction-following capabilities of LLMs, the\nmissing puzzle piece that seems to have not gar-\nnered equal attention from the community is the\nintegration of actual standards or guidelines crafted\nby domain experts as a reference of control. For\nexample, in education and language assessment,\nstandards such as the Common European Frame-\nwork of Reference for Languages (CEFR) serve\nas an accredited guide for administrators in charge\nof the creation of educational curriculum content.\nThis standard provides fine-grained specifications\nof text complexity that different levels of learners\ncan understand depending on their language profi-\nciency (North, 2007, 2014). To be able to automati-\ncally generate text content (e.g., narratives or short\nstories) using an LLM that is acceptable by CEFR\narXiv:2402.12593v2  [cs.CL]  4 Oct 2024", "mimetype": "text/plain", "start_char_idx": 3236, "end_char_idx": 6687, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "279397c8-a63e-4fba-ac64-9123abccafb8": {"__data__": {"id_": "279397c8-a63e-4fba-ac64-9123abccafb8", "embedding": null, "metadata": {"page_label": "2", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "17a68a59-07dd-4e73-80dc-65ccafd2b44d", "node_type": "4", "metadata": {"page_label": "2", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "hash": "675d0cf9bd77be00455507a0474a4f831c5b5eac5078fb42db73e9a8d227804a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "standards and captures a student\u2019s topic interest at\nthe same time can serve as a powerful tool in class-\nroom engagement for educators in the long run.\nThus, this research gap is an opportunity where the\ncomplex instruction-following capabilities of lan-\nguage models can provide assistance, particularly\nfor tasks requiring the generation of text content\nsince this is one of the areas where these models\nobjectively perform well (Chung et al., 2022; Wei\net al., 2021; Gatt and Krahmer, 2018).\nTowards this end, we tackle the main research\nquestion: How can we align large language mod-\nels for content generation tasks using expert-\ndefined standards? We list our major contribu-\ntions from this study as follows:\n1. We introduce STANDARD -CTG , a new task\nformalizing the challenge of generating text\nusing generative language models with expert-\ndefined standards as a for controllability.\n2. We propose STANDARDIZE , a new retrieval-\nstyle in-context learning framework that ex-\ntracts knowledge artifacts from standards such\nas aspect information, exemplars, and manu-\nally crafted linguistic variables to improve the\nperformances of generative language models\nfor content generation.\n3. We introduce significantly improved perfor-\nmances for GPT-4 and Llama for the task\nof STANDARD -CTG using two of the most\nwidely recognized academic standards, CEFR\nand CCS, across diverse evaluation proce-\ndures.\n2 Expert-Defined Standards\n2.1 Background\nAccording to the International Organization for\nStandardization (ISO)2, standards are documented\nguidelines often containing rich detail in describing\nrequirements, specifications, and criteria. These\nguidelines are defined and continuously improved\nby experts in various domains, such as education,\nhealthcare, and accounting, to name a few. Us-\ning standards ensures an institution\u2019s products and\nprocesses are consistent and reproducible (Sadler,\n2017).\nIn the context of education and language assess-\nment, standards are usually in the form of either (a)\n2https://www.iso.org/standards.html\ncontent standards such as documentations of a com-\nmon language for ease of communication, writing,\nand content production, and (b) performance stan-\ndards such as state-administered tests for reading\nand mathematical problem-solving competencies.\nThis study focuses on content-based standards used\nin education and language assessment to be inte-\ngrated into a generative model\u2019s text generation\nprocess. The alignment with existing standards for\nany generated text material is crucial to ensure qual-\nity and consistency before being used in classroom\nsettings (La Marca et al., 2000).\n2.2 Standards in Education and Language\nAssessment\nWe discuss the two selected English standards we\nconsider as test cases for this study.\nThe Common European Framework of Ref-\nerence for Languages (CEFR) is one of the\nwell-known standard language framework 3\ndeveloped by The Council of Europe and used\nfor assessing general language competencies\nsuch as reading, writing, and listening (North,\n2007, 2014). The CEFR uses a six-point level\nscale of A1, A2, B1, B2, C1, and C2, which\ndenotes increasing complexities in instructional\ncontent development. We use the level descriptors\ncompiled by Natova (2021), which cover three\naspects, namely (1) Meaning/Purpose, (2) Struc-\nture, and (3) Grammatical Complexity, describing\nthe characteristics of desired content per level\nas shown in Table 9. We omit a fourth aspect of\nReader\u2019s Knowledge Demands from the standard\nas this heavily depends on the reader\u2019s background\nknowledge and is entirely subjective (Forey, 2020;\nForey and Cheung, 2019).\nThe Common Core Standards (CCS) is an aca-\ndemic standard 4 developed by the US National\nGovernors Association and the Council of Chief\nState School Officers (CCSSO) which has been\nwidely adopted by schools across the United States\nfor its K- 12 curriculum. In this study, we adapt\nthe recommended model of CCS for assessing text\ncomplexity, which includes two main variables: (1)\nQualitative Dimensions and (2) Quantitative Di-\nmensions. However, similar to the CEFR standard,\n3https://www.coe.int/en/web/common-eur\nopean-framework-reference-languages/lev\nel-descriptions\n4https://corestandards.org/", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4230, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "1f55075e-2e8a-4038-bac7-4e5577274b93": {"__data__": {"id_": "1f55075e-2e8a-4038-bac7-4e5577274b93", "embedding": null, "metadata": {"page_label": "3", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "9f1974f9-2e55-433b-98b0-5135dfe73591", "node_type": "4", "metadata": {"page_label": "3", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "hash": "cc0a7e639a49a14a3cc4df4f4adbda34a0e503b538c7a4880037293f5e897340", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "we do not include the last variable, which is Reader\nConsiderations, as this requires professional judg-\nment or a teacher\u2019s intervention. The description\nof each aspect of CCS is detailed in Table 9.\n3 Standard-Aligned Content Generation\n(STANDARD -CTG)\nGiven the importance of adhering to expert-defined\nstandards in the context of language assessment,\nwe introduce a new task we refer to as standard-\naligned content generation (STANDARD -CTG ).\nThe overarching goal of STANDARD -CTG is to\npave the way for new approaches that aim to in-\ntegrate the conventional methodologies of con-\ntrollable text generation in NLP with actual con-\nstraints provided by domain experts across interdis-\nciplinary fields such as education, engineering, and\nmedicine through documented standards. To align\nwith terminologies used in education and other non-\ncomputing literature, in this work, we use the term\ncontent generation instead of text generation as\nusually seen in technical NLP literature.\nWe represent the task ofSTANDARD -CTG using\nthe following formulation:\nSTANDARD -CTG (X, DStandard)\n= L(M\u03b8(X, \u02dcKStandard), E)\n(1)\nwhere L is a general evaluator that tests how\nclose a language model\u2019s M\u03b8 generated content X\nis with gold-standard examples E through learning\ntransformed knowledge representations \u02dcKStandard\nof the selected standard DStandard. The evaluator\nL can assume many forms, including model-based,\ndistance-based, and reference-based scoring. We\npattern our major experiments in the succeeding\nsections based on this formulation.\n4 The S TANDARDIZE Framework\nGiven that expert-defined standards are naturally\ninformation-rich, lengthy, and complex, our main\nhypothesis in this study is that in order for a gen-\nerative language model to produce content that is\naligned with the specifications provided by a stan-\ndard, the information found in the standard must\nbe considered in the generation process. The chal-\nlenge then is redirected towards how any informa-\ntion extracted can be represented as something that\nthe generative model will find useful.\nTowards addressing STANDARD -CTG , we\npropose STANDARDIZE , a retrieval-style in-context\nlearning-based framework that exploits the rich\ninformation found in standards and transforms this\ninto knowledge artifacts to improve the quality of\ncontent produced by generative models. Figure 1\nencapsulates this framework in a visual manner. In\nthe succeeding sections, we discuss the proposed\nSTANDARDIZE framework more thoroughly.\nTarget Specification Extraction is performed\nfirst to obtain informative tags in the prompt and\nto correctly match this information within the\nstandards. For academic standards in language\nassessment, these specifications should provide\ninformation about who will be content delivered to\n(target audience) and using what specific standard\nout of many (CEFR or CCS). Thus, these two\ninformation tags are the basic required input for\nthe process. As an example shown in Figure 1, the\nextracted specifications provided in the prompt are\nA2 readers, which points to a particular group of\nlearners requiring low-leveled reading materials,\nand CEFR scale , which denotes the selected\nstandard where properties of A2-level texts are\ndescribed.\nSpecification Lookup and Retrieval is then\nperformed next upon extracting the target specifi-\ncations. A lookup process is done to find a match\nwith the selected standard, usually in the form of a\ndatabase or an external machine-readable file. In\nthis work, we simply transformed the level-specific\ndescriptors from Natova (2021) into a .csv file.\nThe information from the standard in the form of\naspects (or characteristics) that match the target\nspecifications is then retrieved. The length and\ncomplexity of a standard\u2019s level of information\nregarding its specifications may vary. As shown\nin Figure 1 for the CEFR standard, the retrieved\ninformation that matches the desired level of\ncomplexity for the target audience (A2 readers)\ncan be checked at Table 9.\nKnowledge Augmentation is done last but is the\nmost important process of the pipeline. We propose\na further technical augmentation of information\nfound in standards to obtainknowledge artifacts in\nthe prompts. These knowledge artifacts can range\nfrom simple additional information already present\nin the standard to complex representations, such\nas incorporating actual linguistic features to con-\ntrol the granularity of the generation process. Re-", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4439, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "cb87c01d-4e29-4444-a011-1ecf255da0c1": {"__data__": {"id_": "cb87c01d-4e29-4444-a011-1ecf255da0c1", "embedding": null, "metadata": {"page_label": "4", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "cb5ddc8f-dbda-4557-a840-1e320547a0f2", "node_type": "4", "metadata": {"page_label": "4", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "hash": "bb74ac3460948afe65dcd7f294a31ea8a6568cf6bf01e537442b7515be6ea7bf", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b041f133-4b99-4c99-94ce-0e06bb59d87e", "node_type": "1", "metadata": {}, "hash": "700538f7cf4f31f6731065220a0cea6afa9c79aff84282b0b1bf52cbb6dc796b", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "cent works surveying the performance of open and\nclosed models have shown that non-informative\nstyle of prompting language models, such as the\nteacher style shown in Figure 1, is effective only to\na certain extent and may be biased towards content\ngeneration in lower levels, such as A2 or B1 in the\nCEFR standards (Imperial and Madabushi, 2023;\nRibeiro et al., 2023).\n5 Knowledge Artifacts for STANDARDIZE\nIn this section, we discuss the knowledge artifacts\n\u02dcKStandard extracted from the two educational\nstandards DStandard used in the STANDARDIZE\nframework and how they are integrated into the\ngeneration setup via in-context learning.\nBaseline (Teacher Style) We treat the Teacher\nStyle method as seen in Figure 1, where a\nsimple, non-enriched prompt contains the target\ncategory from each standard, as the baseline for\nperformance. We use this term in observance\nof how non-technical users, especially teachers,\ninteract with generative chat interfaces (Imperial\nand Tayyar Madabushi, 2023).\nAspect Information ( STANDARDIZE -A) repre-\nsents the specific descriptive information provided\nin the standard. In the context of standards for\ncontent generation, aspect information is generally\nattributed to linguistic criteria of content with\nrespect to its target audience. Figure 2 shows how\naspect information from a standard (e.g., CEFR)\ncan be integrated into the actual prompt. The\naddition of aspect criteria information ensures that\nthe generative model will have access to explicit\ncharacteristics of the desired generated content in\ndifferent dimensions.\nLinguistic Flags (STANDARDIZE -L) represent the\ncontrollable attribute-based variables of a standard\nthat a generative model can use to steer the di-\nrection of content generation. In the STANDARD -\nIZE framework, this process serves as a rewrite\nfunction where a generative model is asked to pro-\nduce an initial content first using another method\nprompting (e.g., aspect information in Figure 2),\nand rewrites this by comparing linguistic flag val-\nues of the initially generated content against the\nmean value of a gold standard dataset of the target\nlevel. An example is illustrated in Figure 3 where\nthe mean type-token ratio of a collection of gold-\nGiven this prompt: In the dark old forest up ahead, \na solitary \ufb01gure emerged from the corner of the...\n        \nContinue the story and make sure they are \nreadable for B1 learners in the CEFR scale and \nobserves the following speci\ufb01cations:\n1. Meaning or Purpose: The text is clear and \nconcrete, and tells a simple story.\n2. Structure: The text is can be long but not \ncomplex, and observes mostly chronological with \npossible \ufb02ashbacks.\n3. Grammatical Complexity: The text may contain \nfuture forms, future in the past, repeated actions, \npresent perfect simple forms.\nAspect Criteria\nFigure 2: A standard contains recommended character-\nistics of content across one or more domain-specific\naspects or criteria. This figure shows an example of the\nCEFR standard where the set of criteria includes depth\nof meaning, structure, and grammatical complexity.\nGiven this story: In the dark old forest up ahead, a \nsolitary \ufb01gure emerged from the corner of the...\n        \nRewrite  the story and make sure they are readable \nfor B1 learners in the CEFR scale. Use the \nfollowing linguistic features to reach the target \nlevel of the story:\n1. The type token ratio of the current story is 4.22 \nwhile the mean value in the target level is close to \n12.50 . Increase the complexity by aiming for \nhigher type token ratio.\n2. The average number of words of the current \nstory is 510  while the mean value in the target \nlevel is close to 420 . Decrease the complexity by \naiming for lower average number of words.\nLinguistic Flags \nFigure 3: A standard contains aspect definition which\ncan be represented by flags such as linguistic variables.\nGiven the mean values from gold-standard data in the\ntarget level, the generative model can then be steered to\npush the property of its generated content using direc-\ntional instructions such as increase or decrease.\nstandard B1-level text 12.5 is added to the prompt\nwhile being compared to the current type-token\nvalue of the story, which is 4.2. A verbalizer is\nused to transform the computed linguistic flags into\nnatural language prompts.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4301, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "b041f133-4b99-4c99-94ce-0e06bb59d87e": {"__data__": {"id_": "b041f133-4b99-4c99-94ce-0e06bb59d87e", "embedding": null, "metadata": {"page_label": "4", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "cb5ddc8f-dbda-4557-a840-1e320547a0f2", "node_type": "4", "metadata": {"page_label": "4", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "hash": "bb74ac3460948afe65dcd7f294a31ea8a6568cf6bf01e537442b7515be6ea7bf", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "cb87c01d-4e29-4444-a011-1ecf255da0c1", "node_type": "1", "metadata": {"page_label": "4", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "hash": "af8d2ae3242b5c9f4fadc02bd31a7b3bbc60fa14c4b75b52c5e9f379ce039cd5", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Increase the complexity by aiming for \nhigher type token ratio.\n2. The average number of words of the current \nstory is 510  while the mean value in the target \nlevel is close to 420 . Decrease the complexity by \naiming for lower average number of words.\nLinguistic Flags \nFigure 3: A standard contains aspect definition which\ncan be represented by flags such as linguistic variables.\nGiven the mean values from gold-standard data in the\ntarget level, the generative model can then be steered to\npush the property of its generated content using direc-\ntional instructions such as increase or decrease.\nstandard B1-level text 12.5 is added to the prompt\nwhile being compared to the current type-token\nvalue of the story, which is 4.2. A verbalizer is\nused to transform the computed linguistic flags into\nnatural language prompts. The keywords increase\nand decrease are used in constructing the prompts\nto provide a sense of direction for the generative\nmodel.\nIn this work, we select 2 to 4 linguistic flags\nfor both CEFR and CCS as reported in Table 9.\nThe selection of what linguistic flags to use can\nbe as simple as referring to what the definitions of", "mimetype": "text/plain", "start_char_idx": 3473, "end_char_idx": 4628, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "110f2a8a-2548-4cd3-a50e-80062a6b75e8": {"__data__": {"id_": "110f2a8a-2548-4cd3-a50e-80062a6b75e8", "embedding": null, "metadata": {"page_label": "5", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "9790f12d-8fbb-451b-8f20-e32e7caaf228", "node_type": "4", "metadata": {"page_label": "5", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "hash": "5d020c347c7a39ec67b964caafcbf60b84fa34de44506adca9a69a08cb8e932d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "561673fa-40e0-4c83-a8fe-f9adee1f64b2", "node_type": "1", "metadata": {}, "hash": "c9dc8f2cbee4a123a50c27d0f7b30b85d02f335f19aefe06e48353f589f9587a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Given this prompt: In the dark old forest up ahead, \na solitary \ufb01gure emerged from the corner of the...\n        \nContinue the story and make sure they are \nreadable for B1 learners in the CEFR scale. \nExample books in the same level of complexity \ninclude Frankenstein by Mary Shelley, Wuthering \nHeights by Emily Bronte, and Midsummer Night's \nDream by Shakespeare.\nExemplars\nFigure 4: A standard contains recommended exemplars\nthat serve as gold-standard reference. This figure shows\nan example of the CEFR standard where three well-\nknown pieces of literature are provided as examples of\ncontent that conforms to the target level specified (B1).\naspects provide and need not be exhaustively many.\nFor example, in CEFR, the Organization aspect is\ndefined through different levels as \"text is often\nshort and observes chronological and predictable\nstructure\" for A2 and \"text is can be long but not\ncomplex\" for B1. Thus, we select average sentence\nand word lengths as a linguistic flag to capture\nthis aspect. The full table of average values of\nlinguistic flags can be found in Appendix A.5.\nExemplars ( STANDARDIZE -E) represent the\nrecommended examples by experts or developers\nof standards for reference of users. The addition\nof exemplars or any artifact found in the standard\nthat showcases gold-standard output allows the\ngenerative model to have a sense of implicit\nknowledge during the content generation process.\nFor example, in Figure 4, the exemplars for a\nB1-level content include Frankenstein by Mary\nShelley, a well-known piece of gothic fiction.\nAlthough indirectly, any large language model\ntrained using internet data (e.g., Wikipedia dumps)\nmay have already formed a sense of knowledge\nof how this literature looks like (Karamolegkou\net al., 2023; Petroni et al., 2019). We use the\nactual recommended exemplars from the CCS\nwhile we collected exemplars from the Penguin\nReaders publishing platform 5 which provides\nexpert-curated literature for CEFR. The full list of\nexemplars for both standards can be found in the\nAppendix A.4.\nAll (STANDARDIZE -\u22c6) represents the combination\nof all extract knowledge artifacts mentioned above\nin one prompt.\n5https://www.penguinreaders.co.uk/\n6 Experimental Setup\nIn this section, we detail the specifications and\ntechnical configurations for the study\u2019s main exper-\niments. We also cover information on the datasets\nused, models, and generation tasks.\n6.1 Tasks and Datasets\nFor this study, we specifically center our ex-\nperimentation on the general task of story or\nnarrative generation. We consider the subfield\u2019s\nrich literature and active research community in\nNLP (Alhussain and Azmi, 2021), as well as being\none of the most common examples demonstrated\nacross the education community regarding the\nuse of generative text interfaces for content\ngeneration (Kasneci et al., 2023; Whalen et al.,\n2023). Further, we differentiate two tasks used\nin our work for narrative generation as listed below.\nTask 1: Context Assisted Story Generation .\nFor this setup, we provide preliminary context\nin the form of 50 to 70 words (or approximately\n3 to 5 sentences) in the prompt to guide the\ngenerative language model in producing the\nstory continuation. We select the CEFR as the\nstandard of choice to evaluate this approach\nand use the European Language Grid ( ELG )\ncorpus67 compiled by Breuker (2022) to construct\nthe prompts. The balanced corpus contains 300\nCEFR-aligned English texts produced by experts\nand distributed across five levels A2, B1, B2, C1,\nC2 with 60 instances each. A1 is omitted due to\nlack of resources (n < 20).\nTask 2: Theme Word Story Generation. In con-\ntrast to the previous setup, this method introduces\nonly a single theme word for the generative lan-\nguage to produce a narrative from scratch, which\nallows for increased diversity in the content (Daza\net al., 2016; Peng et al., 2018).", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3871, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "561673fa-40e0-4c83-a8fe-f9adee1f64b2": {"__data__": {"id_": "561673fa-40e0-4c83-a8fe-f9adee1f64b2", "embedding": null, "metadata": {"page_label": "5", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "9790f12d-8fbb-451b-8f20-e32e7caaf228", "node_type": "4", "metadata": {"page_label": "5", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "hash": "5d020c347c7a39ec67b964caafcbf60b84fa34de44506adca9a69a08cb8e932d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "110f2a8a-2548-4cd3-a50e-80062a6b75e8", "node_type": "1", "metadata": {"page_label": "5", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "hash": "46e34b10bf2a1b9c3add9e08879822c529b7afd727f12cc244e66cea06e6b51a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "We select the CEFR as the\nstandard of choice to evaluate this approach\nand use the European Language Grid ( ELG )\ncorpus67 compiled by Breuker (2022) to construct\nthe prompts. The balanced corpus contains 300\nCEFR-aligned English texts produced by experts\nand distributed across five levels A2, B1, B2, C1,\nC2 with 60 instances each. A1 is omitted due to\nlack of resources (n < 20).\nTask 2: Theme Word Story Generation. In con-\ntrast to the previous setup, this method introduces\nonly a single theme word for the generative lan-\nguage to produce a narrative from scratch, which\nallows for increased diversity in the content (Daza\net al., 2016; Peng et al., 2018). To compile a\ntheme words list, we select 50 random English\nnoun words in plural form (e.g., dragons, myster-\nies, voyages) from the Corpus of Contemporary\nAmerican English ( COCA ) (Davies, 2009) and\nprompt the generative model iteratively for each\n6Can be accessed by filling up the form: https://li\nve.european-language-grid.eu/catalogue/c\norpus/9477\n7We note that the ELG corpus is not included in any of\nthe pretraining data reported from the documentation of the\nselected generative models for experimentation, which makes\nit a practical option to be used in this study.", "mimetype": "text/plain", "start_char_idx": 3208, "end_char_idx": 4447, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "35caf51b-bcbf-4bbd-889e-1992400ffb04": {"__data__": {"id_": "35caf51b-bcbf-4bbd-889e-1992400ffb04", "embedding": null, "metadata": {"page_label": "6", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d7be831c-9cf8-4ca3-a7b4-1da140047a95", "node_type": "4", "metadata": {"page_label": "6", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "hash": "6020435dc21f7ed66b20d931a0df99b79b92452ee3ec646bfc72e80cb9d425c0", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a76ec774-8dcf-4aee-b0e3-ee93bc0bfbc1", "node_type": "1", "metadata": {}, "hash": "edb052c1cd412db10a471beb9b14d4148df5c44b15e43c408fca6eb7f64f80d4", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "level in the standard. We investigate the application\nof CCS as the standard of choice in this setup.\n6.2 Models\nWe select a number of generative language mod-\nels M\u03b8 for content generation, each with its own\nadvantage. For the open models, we use a num-\nber of well-known models in the 2B-7B range, in-\ncluding Llama2-Chat-7B (Touvron et al., 2023a),\nOpenChat-7B (Wang et al., 2023), and Longform-\n2.7B (K\u00f6ksal et al., 2023). For the closed model,\nwe use GPT-4-Turbo (OpenAI, 2023). More infor-\nmation on the models can be found in Appendix\nA.3.\n6.3 Automatic Evaluation\nWe perform a diverse set of evaluation methods\nL given examples from gold-standard datasets E\nto test the qualities of the generated content of\nmodels, as discussed further below.\nModel-Based Classifiers. For the context-assisted\nstory generation task using CEFR standards with\n5 classes, we use a Random Forest classifier\ntrained from a separate collection of Cambridge\nExams dataset with CEFR labels used in the\nworks of Xia et al. (2016) and Imperial and\nTayyar Madabushi (2023). This classifier has an\naccuracy of 0.912 using 79 length-normalized8\nlinguistic features. For the theme word story\ngeneration using CCS standards with 2 classes,\nwe used an XGBoost classifier from the work\nof Imperial (2021) trained from the only CCS-\naligned data found online and compiled by Flor\net al. (2013) with an accuracy of 0.917 using a\ncombination of BERT embeddings and the same\nlinguistic features stated above. Due to its limited\nsize of 168, we grouped the dataset into binary\ncategories, elementary (grades 4 \u22128) and advanced\n(grades 9 \u2212 12), with 48 and 73 documents\nper class, respectively. We consider both classi-\nfiers in our work for their high accuracies (> 90%).\nFluency and Diversity . We evaluate the level\nof fluency and content diversity of the generated\ncontent by the models as done in previous narrative\ngeneration works (DeLucia et al., 2021; See et al.,\n2019). The former is measured through perplexity\n8This pertains to using average-based features (e.g., the\naverage count of sentences) in order for the classifier to avoid\nbeing confounded by total-based features (e.g., the total count\nof sentences).\nwith an external GPT-2 model, while the latter is\nthe density of distinct n-grams.\nLinguistic Similarity . We evaluate the level\nof linguistic similarity of the generated content\nagainst the gold-standard datasets for CEFR (ELG)\nand CCS (COCA ) as mentioned in Section 6. For\nthis method, we calculate the mean Euclidean\ndistance of all the linguistic flags used for both\nstandards and their levels listed in Table 9. This\nmethod provides a notion of how close the\ncharacteristics of a set of model-generated texts\n(e.g., GPT-4 generated B1 texts) is to its equivalent\ngold standard (e.g., actual B1-level texts written by\nexperts).\n6.4 Expert Annotator Evaluation\nTo confirm the quality of model-generated content,\nwe also perform an evaluation using judgment\nfrom domain experts. Through our university\nnetwork, we collaborated with three experts with\n15 \u2212 30 years of experience in linguistic and\nlanguage assessment with frameworks such as\nCEFR, CCS, TOEFL, and IELTS. Drawing on\nthe methods used in previous studies (DeLucia\net al., 2021), we asked the experts to judge the\nmodel-generated content through the following\nvariables below. Additional information on the\nhuman evaluation can be found in Appendix A.6.\nGrammaticality and Coherence . The former\nvariable evaluates the level of naturalness or\nfluency of the generated output as if it has been\nwritten by a native English speaker. The latter\nmeasures the level of cohesion between sentences\nwhere the narrative stays on-topic, and the text\noverall builds a consistent story and the flow of\ninformation is smooth and easy to follow.\nGrade Complexity Distinction .", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3819, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "a76ec774-8dcf-4aee-b0e3-ee93bc0bfbc1": {"__data__": {"id_": "a76ec774-8dcf-4aee-b0e3-ee93bc0bfbc1", "embedding": null, "metadata": {"page_label": "6", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d7be831c-9cf8-4ca3-a7b4-1da140047a95", "node_type": "4", "metadata": {"page_label": "6", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "hash": "6020435dc21f7ed66b20d931a0df99b79b92452ee3ec646bfc72e80cb9d425c0", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "35caf51b-bcbf-4bbd-889e-1992400ffb04", "node_type": "1", "metadata": {"page_label": "6", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "hash": "6834f3fb69652f322544e0189af64f52d2339ffbe42d2da46623fa8e7964fea3", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Through our university\nnetwork, we collaborated with three experts with\n15 \u2212 30 years of experience in linguistic and\nlanguage assessment with frameworks such as\nCEFR, CCS, TOEFL, and IELTS. Drawing on\nthe methods used in previous studies (DeLucia\net al., 2021), we asked the experts to judge the\nmodel-generated content through the following\nvariables below. Additional information on the\nhuman evaluation can be found in Appendix A.6.\nGrammaticality and Coherence . The former\nvariable evaluates the level of naturalness or\nfluency of the generated output as if it has been\nwritten by a native English speaker. The latter\nmeasures the level of cohesion between sentences\nwhere the narrative stays on-topic, and the text\noverall builds a consistent story and the flow of\ninformation is smooth and easy to follow.\nGrade Complexity Distinction . This variable\nmeasures the obviousness of the complexity of a\ngenerated story on a target level (e.g., A1) with\nrespect to another story of a different level (e.g.,\nA2). This variable is relatively more challenging\nthan the other metrics, as the difference between\nadjacent levels may not be as straightforward with-\nout referring to the quantitative characteristics of\nthe texts. However, we included this assessment in\nthe evaluation process to judge the quality of the\nmodel-generated texts.", "mimetype": "text/plain", "start_char_idx": 2975, "end_char_idx": 4314, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "1371ab67-915e-4824-ba3f-d8a7c1d1f150": {"__data__": {"id_": "1371ab67-915e-4824-ba3f-d8a7c1d1f150", "embedding": null, "metadata": {"page_label": "7", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "916c726b-bbe1-40ca-bcbd-9a997a1eaa24", "node_type": "4", "metadata": {"page_label": "7", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "hash": "c34934c36fe1953fbdfdc5c2311266c782069e1140dce1ca04fc7f3492eb4d97", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8f61dc97-461e-4bae-9b8f-386c6175fba7", "node_type": "1", "metadata": {}, "hash": "7fd5cfd960797a8435de485a1d1be6f91fb596919c33dacd2531484a652bcb78", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Model Precise\nAccuracy\nAdjacent\nAccuracy\nFluency\n(perplexity)\nDiversity\n(distinct-n)\nLlama2 7B\n- Teacher Style 0.203 0.636 13.189 \u00b14.88 0.156 \u00b10.03\n- STANDARDIZE -A 0.270 0.626 13.694 \u00b17.74 0.155 \u00b10.02\n- STANDARDIZE -E 0.320 0.683 15.576 \u00b13.31 0.188 \u00b10.01\n- STANDARDIZE -L 0.273 0.606 20.175 \u00b14.47 0.186 \u00b10.01\n- STANDARDIZE -\u22c6 0.354 0.670 17.892 \u00b13.94 0.193 \u00b10.01\nOpenChat 7B\n- Teacher Style 0.237 0.626 22.039 \u00b17.70 0.170 \u00b10.02\n- STANDARDIZE -A 0.243 0.630 21.195 \u00b17.66 0.171 \u00b10.02\n- STANDARDIZE -E 0.253 0.600 13.931 \u00b12.97 0.178 \u00b10.01\n- STANDARDIZE -L 0.270 0.546 18.182 \u00b18.52 0.179 \u00b10.02\n- STANDARDIZE -\u22c6 0.253 0.596 12.806 \u00b12.70 0.171 \u00b10.03\nLongform 3B\n- Teacher Style 0.230 0.606 18.209 \u00b16.01 0.159 \u00b10.02\n- STANDARDIZE -A 0.223 0.610 17.982 \u00b19.21 0.157 \u00b10.02\n- STANDARDIZE -E 0.257 0.496 25.075 \u00b18.80 0.192 \u00b10.11\n- STANDARDIZE -L 0.283 0.586 16.926 \u00b16.91 0.161 \u00b10.03\n- STANDARDIZE -\u22c6 0.277 0.543 16.806 \u00b17.40 0.170 \u00b10.04\nGPT-4\n- Teacher Style 0.227 0.630 27.357 \u00b16.30 0.187 \u00b10.08\n- STANDARDIZE -A 0.397 0.846 29.729 \u00b19.58 0.174 \u00b10.01\n- STANDARDIZE -E 0.307 0.703 30.357 \u00b19.79 0.182 \u00b10.01\n- STANDARDIZE -L 0.480 0.906 24.115 \u00b17.04 0.194 \u00b10.03\n- STANDARDIZE -\u22c6 0.540 0.803 22.591 \u00b11.61 0.218 \u00b10.05\nTable 1: Experiment results comparing the conventional\nteacher style prompting with the STANDARDIZE frame-\nwork for the Common European Framework of Reference\nfor Languages (CEFR) standards.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1391, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "8f61dc97-461e-4bae-9b8f-386c6175fba7": {"__data__": {"id_": "8f61dc97-461e-4bae-9b8f-386c6175fba7", "embedding": null, "metadata": {"page_label": "7", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "916c726b-bbe1-40ca-bcbd-9a997a1eaa24", "node_type": "4", "metadata": {"page_label": "7", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "hash": "c34934c36fe1953fbdfdc5c2311266c782069e1140dce1ca04fc7f3492eb4d97", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1371ab67-915e-4824-ba3f-d8a7c1d1f150", "node_type": "1", "metadata": {"page_label": "7", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "hash": "f41bdfac0568031ec666bd997586c21fa1ce7437f3930e884d2f3a46963bf83c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "243f501c-9683-4423-a407-54040b76cf92", "node_type": "1", "metadata": {}, "hash": "3aa1096759ec47387d30452faa5680704e41d81edb4a9edda55e1d49084589d2", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Model Precise\nAccuracy\nFluency\n(perplexity)\nDiversity\n(distinct-n)\nLlama2 7B\n- Teacher Style 0.470 17.936 \u00b14.32 0.184 \u00b10.01\n- STANDARDIZE -A 0.580 22.070 \u00b11.75 0.171 \u00b10.01\n- STANDARDIZE -E 0.570 13.484 \u00b12.50 0.193 \u00b10.01\n- STANDARDIZE -L 0.720 15.066 \u00b12.47 0.191 \u00b10.01\n- STANDARDIZE -\u22c6 0.623 14.707 \u00b12.40 0.193 \u00b10.01\nOpenChat 7B\n- Teacher Style 0.470 16.116 \u00b112.39 0.166 \u00b10.05\n- STANDARDIZE -A 0.550 19.444 \u00b12.57 0.172 \u00b10.01\n- STANDARDIZE -E 0.490 12.438 \u00b11.85 0.178 \u00b10.01\n- STANDARDIZE -L 0.580 13.734 \u00b12.53 0.180 \u00b10.01\n- STANDARDIZE -\u22c6 0.560 10.717 \u00b11.53 0.169 \u00b10.01\nLongform 3B\n- Teacher Style 0.500 13.657 \u00b15.39 0.154 \u00b10.04\n- STANDARDIZE -A 0.450 17.918 \u00b14.74 0.148 \u00b10.01\n- STANDARDIZE -E 0.510 14.277 \u00b12.79 0.151 \u00b10.02\n- STANDARDIZE -L 0.610 13.398 \u00b13.93 0.148 \u00b10.04\n- STANDARDIZE -\u22c6 0.620 10.400 \u00b11.53 0.169 \u00b10.01\nGPT-4\n- Teacher Style 0.590 32.447 \u00b17.46 0.195 \u00b10.01\n- STANDARDIZE -A 0.550 31.765 \u00b111.30 0.169 \u00b10.01\n- STANDARDIZE -E 0.520 29.912 \u00b16.81 0.184 \u00b10.01\n- STANDARDIZE -L 0.610 26.912 \u00b16.11 0.155 \u00b10.01\n- STANDARDIZE -\u22c6 0.790 21.277 \u00b14.50 0.198 \u00b10.01\nTable 2: Experiment results comparing the conven-\ntional teacher style prompting with the STANDARD -\nIZE framework for the Common Core Standards\n(CCS).\n7 Results and Discussion\nWe discuss the results of our experiments proce-\ndures with the methods from the STANDARDIZE\nframework.\n7.1 Standard Alignment via Classification\nPerformance\nThe overall performance of models for CEFR and\nCCS are reported in Tables 1 and 2. For CEFR,\nthe top-performing setup across the four models\nall belong to the STANDARDIZE framework. We\nreport over a 100% increase in performance using\nthe best setup with GPT-4 with STANDARDIZE -\u22c6\nin precise accuracy from 0.227 to 0.540 and a 43%\nincrease for adjacent accuracy from 0.630 to 0.906\ncompared to the teacher style method. Through\nSTANDARDIZE , open models also gained substan-\ntial boosts in performance, such as Longform up\nby 23%, OpenChat up by 14%, and Llama2 by\n74%. In terms of adjacent accuracies, GPT-4 re-\nmained the best model for preserving the ordinal-\nity of the labels with 0.906, up by 44%. With\nCCS, the general scores obtained in this setup are\nhigher compared to CEFR with five classes due to\nbinary labeling. We see a similar pattern where\nall open and closed models obtained the best per-\nformance, with boosts ranging from 3% to 45%\nusing linguistic flags STANDARDIZE -L and a com-\nbination of all knowledge artifacts STANDARD -\nIZE -\u22c6 to refine the generated content toward the\ntarget level. From these findings, we provide con-\ncrete evidence that using the actual content of\nthe standards through knowledge artifact repre-\nsentations from STANDARDIZE may be crucial\nwhen prompting LLMs via in-context learning to\nproduce standard-aligned content for classroom\nuse.", "mimetype": "text/plain", "start_char_idx": 1392, "end_char_idx": 4177, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "243f501c-9683-4423-a407-54040b76cf92": {"__data__": {"id_": "243f501c-9683-4423-a407-54040b76cf92", "embedding": null, "metadata": {"page_label": "7", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "916c726b-bbe1-40ca-bcbd-9a997a1eaa24", "node_type": "4", "metadata": {"page_label": "7", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "hash": "c34934c36fe1953fbdfdc5c2311266c782069e1140dce1ca04fc7f3492eb4d97", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8f61dc97-461e-4bae-9b8f-386c6175fba7", "node_type": "1", "metadata": {"page_label": "7", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "hash": "f23bb93a1044f5d3f65fe0c652a77baf93971922e1ee9f2fd7987c6ad2be8fd3", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "In terms of adjacent accuracies, GPT-4 re-\nmained the best model for preserving the ordinal-\nity of the labels with 0.906, up by 44%. With\nCCS, the general scores obtained in this setup are\nhigher compared to CEFR with five classes due to\nbinary labeling. We see a similar pattern where\nall open and closed models obtained the best per-\nformance, with boosts ranging from 3% to 45%\nusing linguistic flags STANDARDIZE -L and a com-\nbination of all knowledge artifacts STANDARD -\nIZE -\u22c6 to refine the generated content toward the\ntarget level. From these findings, we provide con-\ncrete evidence that using the actual content of\nthe standards through knowledge artifact repre-\nsentations from STANDARDIZE may be crucial\nwhen prompting LLMs via in-context learning to\nproduce standard-aligned content for classroom\nuse.\n7.2 Standard Alignment via Linguistic\nSimilarity\nWe visualize the distributions of the best perform-\ning STANDARDIZE methods in Figures 6 to 8 with\ncomparison to the teacher style method. From the\nresults, we observe that the general trend of using\nSTANDARDIZE produces a more stable distribu-\ntion across the variables it is explicitly controlling\nfor (e.g., average sentence length or type token di-\nversity as listed in Table 9), particularly with the\nCCS standards. We also notice that the distribu-\ntions using STANDARDIZE -L also produce distri-\nbutions closer to the mean (represented as a yellow\nstar) from their corresponding gold-standard data.\nMoreover, in terms of linguistic similarity, as re-\nported in Table 3,STANDARDIZE makes the quality\nof model generations more similar to the linguis-\ntic characteristics of the gold standard datasets in", "mimetype": "text/plain", "start_char_idx": 3361, "end_char_idx": 5035, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "91b29eea-77af-4e13-acfe-8d3acbebb661": {"__data__": {"id_": "91b29eea-77af-4e13-acfe-8d3acbebb661", "embedding": null, "metadata": {"page_label": "8", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "e4dc0552-1ed3-4566-a1ab-df63dfd74b04", "node_type": "4", "metadata": {"page_label": "8", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "hash": "c2d099b7cbca92df31eeb2ec4744beb47c9d2a1afb6532b1c86cf4e8c7b7bc82", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "CEFR and CCS. Overall, these findings further\nstrengthen the evidence of using STANDARDIZE\nin producing linguistically similar content with\ngold-standard data compared to the conventional\nteacher style method.\nSetup A2 B1 B2 C1 C2\nTeacher Style 136.7 96.7 169.9 307.3 291.6\nSTANDARDIZE -\u22c6 61.4 106.2 97.64 219.6 234.7\nSetup Elementary Advanced\nTeacher Style 76.1 157.9\nSTANDARDIZE -\u22c6 63.8 125.7\nTable 3: Mean Euclidean distances of generated content\nusing simple teacher style prompting vs. STANDARD -\nIZE -\u22c6 for CEFR (top) and CCS (bottom).\n7.3 Assessment of Generation Qualities via\nExpert Judgment and Automatic Metrics\nFor both computed fluency and content diversity,\nwe see similar results from the previous evaluation\ntechniques where the best performing models are\nall models improved through the STANDARDIZE\nframework particularly OpenChat, Longform, and\nGPT-4. Looking at expert evaluations as reported\nin Figure 5, we observe consistent high ratings on\ngrammaticality and coherence of the topi perform-\ning model, GPT-4 with STANDARDIZE -\u22c6, for both\nCEFR and CCS with an average of 3.13 and 3.35,\nrespectively. On the grade complexity distinction,\nall three expert evaluators were able to achieve high\naccuracies (> 0.70) in selecting correct simple and\ncomplex texts from the model-generated data, de-\nnoting the obviousness of complexity. Likewise, all\nexpert evaluation tests achieved strong inter-rater\nreliability scores ( > 0.30) through Kendall\u2019s W\n(Kendall, 1948). With these findings, we affirm\nthe effectivity of the STANDARDIZE framework\nthrough expert judgment on generating more\nfluent, grammatical, grade-distinct, and diverse\ncontent compared to the teacher-style approach.\n8 Implications to Generative Models for\nEducation\nWe discuss important points highlighting the\nreal-world implications of our study within and\nbeyond language model experimentations.\nValidity on Global Education Context . Our\nmain contribution, the STANDARDIZE framework,\nleverages the idea of a more holistic method\nfor capturing the intricacies and complexities of\neducational standards for content generation. Our\nexperiments with the CEFR and CCS standards\nshowcase an opportunity for the generated texts of\nlanguage model interfaces such as GPT-4, which\nare commonly used by educators and teachers, to\nbe aligned with international language proficiency\nlevels. Moreover, showing the effectiveness of\nSTANDARDIZE on the aforementioned interna-\ntionally recognized academic standards used\nin European and Northern American schools\nsignifies the framework\u2019s strong potential for\ncross-curricula application. Thus, we invite future\nresearchers to explore, validate, and propose\nderivations of our base framework for their own\nlanguages and language-specific standards for\ncontent generation.\nTowards More Personalized Content Genera-\ntion. Investigating the potential of generative mod-\nels for personalized learning, such as providing\nadaptive feedback aligned with students\u2019 needs, is\nan active area in AI for education (Kasneci et al.,\n2023; Meyer et al., 2023; Sailer et al., 2023; Tack\nand Piech, 2022). This work contributes toward\nthe goal of helping educators craft more personal-\nized content for learners using the capabilities of\nlarge language models based on an assigned lan-\nguage proficiency level described by a standard.\nWhile we present a novel task specifically targeted\nfor the NLP community to encourage research in\nthis direction (STANDARD -CTG as covered in Sec-\ntion 3), our results may be useful for educators by\nproviding context on better methods for generating\nlevel or target audience-specific texts by prompt-\ning language models using information found in\neducational standards.\n9 Related Work\nResearch in complexity-controlled generation has\nexplored diverse variables in terms of text for-\nmat, granularity, and task variation. The work of\nAgrawal and Carpuat (2019) introduced controlling\nfor specific complexity in the machine translation\ntask. The following works of Agrawal and Carpuat\n(2023) and Ribeiro et al. (2023) explored grade-\nspecific text simplification and summarization us-\ning control tokens and reinforcement learning, re-\nspectively. Currently, only two works have inves-\ntigated incorporating CEFR for language learning\ncontent generation. Stowe et al. (2022) and Impe-", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4322, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "fd216069-f79f-4890-9595-d44086a8b2d5": {"__data__": {"id_": "fd216069-f79f-4890-9595-d44086a8b2d5", "embedding": null, "metadata": {"page_label": "9", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "5e69ed8e-a68c-4097-ac57-173fd1043951", "node_type": "4", "metadata": {"page_label": "9", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "hash": "ff2b0cffe032ccd345dbec925e6e021de7b98a87e29573cfa74ef8d0d1fc859f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "3b8e3c46-138f-4bca-851e-b8d03f34f6e0", "node_type": "1", "metadata": {}, "hash": "e9dc565ba06ee0ff8b1a9304282834972ecab9e25c981f07d6d1f51a1617377f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "3.1\n3.5\n3.1 3.0 3.13.0\n3.4\n3.1 2.9 3.1\n0.0\n0.5\n1.0\n1.5\n2.0\n2.5\n3.0\n3.5\n4.0\nA2 B1 B2 C1 C2\nGrammaticality Coherence\n(a) Expert evaluation on the generation qual-\nity of the GPT-4 model with STANDARD -\nIZE -\u22c6 for CEFR. Inter-rater reliability using\nKendall\u2019s W is 0.34 which denotes moder-\nate agreement.\n3.3 3.33.4 3.3\n0.0\n0.5\n1.0\n1.5\n2.0\n2.5\n3.0\n3.5\n4.0\nElementary Advanced\nGrammaticality Coherence\n(b) Expert evaluation on the gen-\neration quality of the GPT-4\nmodel with STANDARDIZE -\u22c6 for\nCCS. Inter-rater reliability using\nKendall\u2019s W is 0.40 which denotes\nstrong agreement\n0.8\n0.8\n0.7\n0.9\n0.7\n1.0\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nExpert 1 Expert 2 Expert 3\nCEFR CCS\n(c) Performance of expert evaluators on\nestimating the complexity of generated\ncontent for CEFR and CCS. Inter-rater re-\nliability using Kendall\u2019sW is 0.45 which\ndenotes strong agreement.\nFigure 5: Overview of mean ratings of grammaticality or fluency, coherence, and grade complexity distinction from\nthe human expert evaluations using the top-performing models for CEFR and CCS. All evaluation procedures obtain\ngenerally favorable results as well as acceptable inter-rater reliability scores (equal and above the threshold of 0.30)\n.\nrial and Tayyar Madabushi (2023) both made use\nof CEFR-aligned text for NLG. However, none of\nthem made use of the actual guideline information\nfound in CEFR during the generation process.\nOur study\u2019s main novelty is the holistic capture\nof expert-defined standards by exploring possible\nrepresentations we call artifacts that can improve\nhow a language model refines its content genera-\ntion process with respect to a target language pro-\nficiency level. We emphasize the importance of\nthe use of in-context learning without additional\nfinetuning in this work to preserve the capabilities\nof models across other language-related tasks. Our\nSTANDARDIZE framework derives motivation from\nZhou et al. (2023) and Ram et al. (2023), where\na verbalizer is used to transform quantitative con-\nstraints into natural language for prompting, as well\nas the use of a lookup and retrieval phase where as-\npect information is added in the prompt to influence\nmodel controllability.\n10 Conclusion\nIn this work, we proposed the STANDARDIZE\nframework using knowledge artifacts that allowed\nlarge language models such as Llama2 and GPT-\n4 to gain significant performance boosts ( 45% -\n100%) on generating content aligned with educa-\ntional standards as well as preserving important\nnarrative qualities such as fluency, grammaticality,\ncoherence, and grade distinctness. From this, we\nsee a very promising potential for cross-domain\nand cross-standard generalization of our proposed\nmethod with the range of educational contexts\naround the world and invite future work to build on\nour baseline models.\nEthical Considerations\nAll datasets and corpora used in this study, such\nas the ELG (Breuker, 2022), Cambridge Exams\n(Xia et al., 2016), and CCS (Flor et al., 2013), are\nalready established and accessible for research pur-\nposes. We observe a specific tone in the discussion\nof our experiments, emphasizing that the main mo-\ntivation of the work is that language models such as\nGPT-4 can provide assistance in producing content\nthat is more aligned or faithful with the constraints\nof standards such as CEFR or CCS without im-\nplying that they can replace experts in the field or\nproduce better quality than the gold-standard data.\nFurther, we also do not imply that any model en-\nriched by any computational method to produce\nmore standard-aligned content can replace the stan-\ndard itself. Overall, we do not foresee any serious\nethical issues in this study.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3645, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "3b8e3c46-138f-4bca-851e-b8d03f34f6e0": {"__data__": {"id_": "3b8e3c46-138f-4bca-851e-b8d03f34f6e0", "embedding": null, "metadata": {"page_label": "9", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "5e69ed8e-a68c-4097-ac57-173fd1043951", "node_type": "4", "metadata": {"page_label": "9", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "hash": "ff2b0cffe032ccd345dbec925e6e021de7b98a87e29573cfa74ef8d0d1fc859f", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "fd216069-f79f-4890-9595-d44086a8b2d5", "node_type": "1", "metadata": {"page_label": "9", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "hash": "bb37334228164df2ab471bbe441e39cbe5083b27926b0e27565003ee00f38dfa", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "We observe a specific tone in the discussion\nof our experiments, emphasizing that the main mo-\ntivation of the work is that language models such as\nGPT-4 can provide assistance in producing content\nthat is more aligned or faithful with the constraints\nof standards such as CEFR or CCS without im-\nplying that they can replace experts in the field or\nproduce better quality than the gold-standard data.\nFurther, we also do not imply that any model en-\nriched by any computational method to produce\nmore standard-aligned content can replace the stan-\ndard itself. Overall, we do not foresee any serious\nethical issues in this study.\nLimitations\nLanguage Coverage of Standards . This work\nis mainly centered on the use of datasets and\nstandards for the English language. While\nstandards for language assessment, such as CEFR,\nhave expanded through the years with versions to\ncover other languages, such as German, Czech,\nand Italian (Vajjala and Rama, 2018), we do not\nclaim that our results will be able to generalize and", "mimetype": "text/plain", "start_char_idx": 3015, "end_char_idx": 4034, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "1387d259-896f-46eb-966f-9d214a84f332": {"__data__": {"id_": "1387d259-896f-46eb-966f-9d214a84f332", "embedding": null, "metadata": {"page_label": "10", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2a32a8f1-3309-4bf4-9559-b165fc1af324", "node_type": "4", "metadata": {"page_label": "10", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "hash": "395775259f2aeb9a524c15aa994a2c43745ea1e5c2d1645771dba7d049cd19dd", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e0a0bc8b-9fdd-4763-9c72-f43301a7aaf7", "node_type": "1", "metadata": {}, "hash": "eb77e4a6b874b96882d3447f61f7621bf00a0cc9a0bc579d95436f222359dd30", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "have the same advantages with these languages.\nHowever, investigating this direction may be a\ngood research opportunity for future work.\nDependence on Evaluation Methods . As\nobserved in Section 7, we made sure to cover\na variety of evaluation procedures for testing\nstandard alignment instead of only using model-\nbased methods such as a classifier. The limitation\nhere is that trained classifiers are dependent on\nfactors such as their accuracy, the quantity of\ndata, the complexity of the training algorithm,\nand the quality of features. Thus, other means of\nevaluating alignment that is more direct, such as\ncomputed feature distances against a gold-standard\ndataset, is always recommended. Moreover, our\nmodel-based CEFR and CCS evaluators make use\nof artifacts such as datasets and tools for feature\nextraction from peer-reviewed papers (Xia et al.,\n2016; Flor et al., 2013). We are aware of paid\nthird-party services online that promise more\naccurate classification of labels in CEFR, but\nthey generally do not provide details on linguistic\npredictors used for prediction. Thus, this may not\nbe a practical option for research.\nAttribute-Based Standards. The standards used\nin this study, CEFR and CCS, are attribute-based\nstandards that specify recommended characteristics\nof texts that are countable (e.g., sentence length or\naverage number of words). These specifications\ncontribute towards the overall complexity of texts\nwhich are within the scope of CEFR and CCS. Stan-\ndards in other domains may come in different forms\nof constraints, such as dependence on an exter-\nnal specialized vocabulary or following specific\nsequential processes to arrive at a result. More-\nover, our exploration of CEFR and CCS standards\nis centered on the downstream task of narrative gen-\neration, as this fits the most generic form of reading\nmaterial in classrooms. We leave the exploration of\nextending the STANDARDIZE framework to other\ndomains that also observe attribute-based specifica-\ntions as well as other adjacent text generation tasks\n(e.g., summary generation) in future work.\nAcknowledgements\nWe are grateful to the anonymous reviewers and\nAction Editors in ARR for their feedback on the\nimprovement of this paper and to Dr. Brian North\nfor the insightful discussions on capturing language\nstandards, including CEFR, as part of the theoret-\nical component of this work. We also thank Dr.\nSamantha Curle and Dr. Reka Jablonkai from the\nDepartment of Education at the University of Bath\nfor helping with the evaluation of model-generated\ntexts. This work made use of the Hex GPU cloud\nof the Department of Computer Science at the Uni-\nversity of Bath. JMI is supported by the National\nUniversity Philippines and the UKRI Centre for\nDoctoral Training in Accountable, Responsible,\nand Transparent AI [EP/S023437/1] of the Uni-\nversity of Bath. We attribute the black icons used\nin Figure 1 to the collections of Design Circle and\nVictor Zukeran from the Noun Project and the col-\nored teacher icon from Flaticon.\nReferences\nSweta Agrawal and Marine Carpuat. 2019. Controlling\nText Complexity in Neural Machine Translation. In\nProceedings of the 2019 Conference on Empirical\nMethods in Natural Language Processing and the\n9th International Joint Conference on Natural Lan-\nguage Processing (EMNLP-IJCNLP), pages 1549\u2013\n1564, Hong Kong, China. Association for Computa-\ntional Linguistics.\nSweta Agrawal and Marine Carpuat. 2023. Control-\nling Pre-trained Language Models for Grade-Specific\nText Simplification. In Proceedings of the 2023 Con-\nference on Empirical Methods in Natural Language\nProcessing, pages 12807\u201312819, Singapore. Associ-\nation for Computational Linguistics.\nArwa I Alhussain and Aqil M Azmi. 2021. Automatic\nStory Generation: A Survey of Approaches. ACM\nComputing Surveys (CSUR), 54(5):1\u201338.\nMark Breuker. 2022. CEFR Labelling and Assessment\nServices. In European Language Grid: A Language\nTechnology Platform for Multilingual Europe, pages\n277\u2013282. Springer International Publishing Cham.\nHyung Won Chung, Le Hou, Shayne Longpre, Bar-\nret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi\nWang, Mostafa Dehghani, Siddhartha Brahma, et al.\n2022.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4162, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e0a0bc8b-9fdd-4763-9c72-f43301a7aaf7": {"__data__": {"id_": "e0a0bc8b-9fdd-4763-9c72-f43301a7aaf7", "embedding": null, "metadata": {"page_label": "10", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2a32a8f1-3309-4bf4-9559-b165fc1af324", "node_type": "4", "metadata": {"page_label": "10", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "hash": "395775259f2aeb9a524c15aa994a2c43745ea1e5c2d1645771dba7d049cd19dd", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1387d259-896f-46eb-966f-9d214a84f332", "node_type": "1", "metadata": {"page_label": "10", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "hash": "ea19e34fa83ac13688d1643edce4e3240280b490d915a0897a4ae758e80f41b1", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "In Proceedings of the 2023 Con-\nference on Empirical Methods in Natural Language\nProcessing, pages 12807\u201312819, Singapore. Associ-\nation for Computational Linguistics.\nArwa I Alhussain and Aqil M Azmi. 2021. Automatic\nStory Generation: A Survey of Approaches. ACM\nComputing Surveys (CSUR), 54(5):1\u201338.\nMark Breuker. 2022. CEFR Labelling and Assessment\nServices. In European Language Grid: A Language\nTechnology Platform for Multilingual Europe, pages\n277\u2013282. Springer International Publishing Cham.\nHyung Won Chung, Le Hou, Shayne Longpre, Bar-\nret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi\nWang, Mostafa Dehghani, Siddhartha Brahma, et al.\n2022. Scaling Instruction-Finetuned Language Mod-\nels. arXiv preprint arXiv:2210.11416.\nMark Davies. 2009. The 385+ million word Corpus\nof Contemporary American English (1990\u20132008+):\nDesign, architecture, and linguistic insights. Interna-\ntional Journal of Corpus Linguistics, 14(2):159\u2013190.\nAngel Daza, Hiram Calvo, and Jes\u00fas Figueroa-Nazuno.\n2016. Automatic Text Generation by Learning from\nLiterary Structures. In Proceedings of the Fifth Work-\nshop on Computational Linguistics for Literature ,\npages 9\u201319, San Diego, California, USA. Associa-\ntion for Computational Linguistics.", "mimetype": "text/plain", "start_char_idx": 3512, "end_char_idx": 4740, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "b75389bd-45f0-4718-8d9a-9d499650b2de": {"__data__": {"id_": "b75389bd-45f0-4718-8d9a-9d499650b2de", "embedding": null, "metadata": {"page_label": "11", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "31098157-5ff6-4a52-9c35-320781ea3bd4", "node_type": "4", "metadata": {"page_label": "11", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "hash": "9164fe4cd56d6deec96fff90a0a283485ab94fa498d763518717ef1b317192bc", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d9d4aa39-9b9e-48c5-9141-692b358b22c0", "node_type": "1", "metadata": {}, "hash": "7b0fe3c4cd65fa13479c783ee3c4617805ab86fbaa707d967512b6149688e3ce", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Alexandra DeLucia, Aaron Mueller, Xiang Lisa Li, and\nJo\u00e3o Sedoc. 2021. Decoding Methods for Neural\nNarrative Generation. In Proceedings of the 1st Work-\nshop on Natural Language Generation, Evaluation,\nand Metrics (GEM 2021) , pages 166\u2013185, Online.\nAssociation for Computational Linguistics.\nAngela Fan, Mike Lewis, and Yann Dauphin. 2018. Hi-\nerarchical Neural Story Generation. In Proceedings\nof the 56th Annual Meeting of the Association for\nComputational Linguistics (Volume 1: Long Papers),\npages 889\u2013898, Melbourne, Australia. Association\nfor Computational Linguistics.\nMichael Flor, Beata Beigman Klebanov, and Kath-\nleen M. Sheehan. 2013. Lexical Tightness and Text\nComplexity. In Proceedings of the Workshop on\nNatural Language Processing for Improving Textual\nAccessibility, pages 29\u201338, Atlanta, Georgia. Associ-\nation for Computational Linguistics.\nGail Forey. 2020. A whole school approach to SFL\nmetalanguage and the explicit teaching of language\nfor curriculum learning. Journal of English for Aca-\ndemic Purposes, 44:100822.\nGail Forey and Lok Ming Eric Cheung. 2019. The ben-\nefits of explicit teaching of language for curriculum\nlearning in the physical education classroom. English\nfor Specific Purposes, 54:91\u2013109.\nAlbert Gatt and Emiel Krahmer. 2018. Survey of the\nState of the Art in Natural Language Generation:\nCore tasks, applications and evaluation. Journal of\nArtificial Intelligence Research, 61:65\u2013170.\nJoseph Marvin Imperial. 2021. BERT embeddings for\nautomatic readability assessment. In Proceedings of\nthe International Conference on Recent Advances in\nNatural Language Processing (RANLP 2021), pages\n611\u2013618, Held Online. INCOMA Ltd.\nJoseph Marvin Imperial and Harish Tayyar Madabushi.\n2023. Uniform Complexity for Text Generation. In\nFindings of the Association for Computational Lin-\nguistics: EMNLP 2023, pages 12025\u201312046, Singa-\npore. Association for Computational Linguistics.\nJoseph Marvin Imperial and Harish Tayyar Madabushi.\n2023. Flesch or fumble? evaluating readability stan-\ndard alignment of instruction-tuned language mod-\nels. In Proceedings of the Third Workshop on Natu-\nral Language Generation, Evaluation, and Metrics\n(GEM), pages 205\u2013223, Singapore. Association for\nComputational Linguistics.\nAntonia Karamolegkou, Jiaang Li, Li Zhou, and An-\nders S\u00f8gaard. 2023. Copyright Violations and Large\nLanguage Models. In Proceedings of the 2023 Con-\nference on Empirical Methods in Natural Language\nProcessing, pages 7403\u20137412, Singapore. Associa-\ntion for Computational Linguistics.\nEnkelejda Kasneci, Kathrin Se\u00dfler, Stefan K\u00fcchemann,\nMaria Bannert, Daryna Dementieva, Frank Fischer,\nUrs Gasser, Georg Groh, Stephan G\u00fcnnemann, Eyke\nH\u00fcllermeier, et al. 2023. ChatGPT for Good? On\nOpportunities and Challenges of Large Language\nModels for Education. Learning and Individual Dif-\nferences, 103:102274.\nMaurice George Kendall. 1948. Rank correlation meth-\nods. American Psychological Association.\nAbdullatif K\u00f6ksal, Timo Schick, Anna Korhonen, and\nHinrich Sch\u00fctze. 2023. LongForm: Optimizing In-\nstruction Tuning for Long Text Generation with Cor-\npus Extraction. arXiv preprint arXiv:2304.08460.\nPaul M La Marca, Doris Redfield, and Phoebe C Winter.\n2000. State Standards and State Assessment Sys-\ntems: A Guide to Alignment. Series on Standards\nand Assessments. Non-Journal.\nBruce W. Lee and Jason Lee. 2023. LFTK: Handcrafted\nFeatures in Computational Linguistics. In Proceed-\nings of the 18th Workshop on Innovative Use of NLP\nfor Building Educational Applications (BEA 2023),\npages 1\u201319, Toronto, Canada. Association for Com-\nputational Linguistics.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3600, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "d9d4aa39-9b9e-48c5-9141-692b358b22c0": {"__data__": {"id_": "d9d4aa39-9b9e-48c5-9141-692b358b22c0", "embedding": null, "metadata": {"page_label": "11", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "31098157-5ff6-4a52-9c35-320781ea3bd4", "node_type": "4", "metadata": {"page_label": "11", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "hash": "9164fe4cd56d6deec96fff90a0a283485ab94fa498d763518717ef1b317192bc", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b75389bd-45f0-4718-8d9a-9d499650b2de", "node_type": "1", "metadata": {"page_label": "11", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "hash": "f4ea70ee4be97d51d1f394f84e6ca9286d025d1e97a3a3bcc132ac966add699f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "American Psychological Association.\nAbdullatif K\u00f6ksal, Timo Schick, Anna Korhonen, and\nHinrich Sch\u00fctze. 2023. LongForm: Optimizing In-\nstruction Tuning for Long Text Generation with Cor-\npus Extraction. arXiv preprint arXiv:2304.08460.\nPaul M La Marca, Doris Redfield, and Phoebe C Winter.\n2000. State Standards and State Assessment Sys-\ntems: A Guide to Alignment. Series on Standards\nand Assessments. Non-Journal.\nBruce W. Lee and Jason Lee. 2023. LFTK: Handcrafted\nFeatures in Computational Linguistics. In Proceed-\nings of the 18th Workshop on Innovative Use of NLP\nfor Building Educational Applications (BEA 2023),\npages 1\u201319, Toronto, Canada. Association for Com-\nputational Linguistics.\nJesse G Meyer, Ryan J Urbanowicz, Patrick CN Mar-\ntin, Karen O\u2019Connor, Ruowang Li, Pei-Chen Peng,\nTiffani J Bright, Nicholas Tatonetti, Kyoung Jae Won,\nGraciela Gonzalez-Hernandez, et al. 2023. Chatgpt\nand large language models in academia: opportuni-\nties and challenges. BioData Mining, 16(1):20.\nIvanka Natova. 2021. Estimating CEFR Reading Com-\nprehension Text Complexity. The Language Learn-\ning Journal, 49(6):699\u2013710.\nBrian North. 2007. The CEFR Illustrative Descriptor\nScales. The Modern Language Journal, 91(4):656\u2013\n659.\nBrian North. 2014. The CEFR in practice, volume 4.\nCambridge University Press.\nOpenAI. 2023. GPT-4 Technical Report. arXiv preprint\narXiv:2303.08774.\nLong Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,\nCarroll Wainwright, Pamela Mishkin, Chong Zhang,\nSandhini Agarwal, Katarina Slama, Alex Ray, et al.\n2022. Training language models to follow instruc-\ntions with human feedback. Advances in Neural\nInformation Processing Systems, 35:27730\u201327744.\nNanyun Peng, Marjan Ghazvininejad, Jonathan May,\nand Kevin Knight. 2018. Towards Controllable Story\nGeneration. In Proceedings of the First Workshop on\nStorytelling, pages 43\u201349, New Orleans, Louisiana.\nAssociation for Computational Linguistics.\nFabio Petroni, Tim Rockt\u00e4schel, Sebastian Riedel,\nPatrick Lewis, Anton Bakhtin, Yuxiang Wu, and\nAlexander Miller. 2019. Language Models as Knowl-\nedge Bases? In Proceedings of the 2019 Confer-\nence on Empirical Methods in Natural Language Pro-\ncessing and the 9th International Joint Conference\non Natural Language Processing (EMNLP-IJCNLP),", "mimetype": "text/plain", "start_char_idx": 2907, "end_char_idx": 5162, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "5059f07b-53fc-4c41-b737-4e7bc32ea580": {"__data__": {"id_": "5059f07b-53fc-4c41-b737-4e7bc32ea580", "embedding": null, "metadata": {"page_label": "12", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "40542742-aec1-423e-8af1-02002e279650", "node_type": "4", "metadata": {"page_label": "12", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "hash": "fd1cdf2318c8ed31afa3d475a59e79ee5a0e4b44d8b6a2d040fcc25505917c89", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "701b18cc-e46a-4173-9dbd-ae51764b94d9", "node_type": "1", "metadata": {}, "hash": "61d944d15801c8e7ba39b0161e57ccc7763839405687c8640e19429a9a43507e", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "pages 2463\u20132473, Hong Kong, China. Association\nfor Computational Linguistics.\nOri Ram, Yoav Levine, Itay Dalmedigos, Dor Muhlgay,\nAmnon Shashua, Kevin Leyton-Brown, and Yoav\nShoham. 2023. In-Context Retrieval-Augmented\nLanguage Models. Transactions of the Association\nfor Computational Linguistics, 11:1316\u20131331.\nLeonardo F. R. Ribeiro, Mohit Bansal, and Markus\nDreyer. 2023. Generating Summaries with Control-\nlable Readability Levels. In Proceedings of the 2023\nConference on Empirical Methods in Natural Lan-\nguage Processing, pages 11669\u201311687, Singapore.\nAssociation for Computational Linguistics.\nD Royce Sadler. 2017. Academic achievement stan-\ndards and quality assurance. Quality in Higher Edu-\ncation, 23(2):81\u201399.\nMichael Sailer, Elisabeth Bauer, Riikka Hofmann, Jan\nKiesewetter, Julia Glas, Iryna Gurevych, and Frank\nFischer. 2023. Adaptive feedback from artificial neu-\nral networks facilitates pre-service teachers\u2019 diagnos-\ntic reasoning in simulation-based learning. Learning\nand Instruction, 83:101620.\nVictor Sanh, Albert Webson, Colin Raffel, Stephen\nBach, Lintang Sutawika, Zaid Alyafeai, Antoine\nChaffin, Arnaud Stiegler, Arun Raja, Manan Dey,\net al. 2021. Multitask Prompted Training Enables\nZero-Shot Task Generalization. In International Con-\nference on Learning Representations.\nAbigail See, Aneesh Pappu, Rohun Saxena, Akhila\nYerukola, and Christopher D. Manning. 2019. Do\nMassively Pretrained Language Models Make Better\nStorytellers? In Proceedings of the 23rd Confer-\nence on Computational Natural Language Learning\n(CoNLL), pages 843\u2013861, Hong Kong, China. Asso-\nciation for Computational Linguistics.\nKevin Stowe, Debanjan Ghosh, and Mengxuan Zhao.\n2022. Controlled Language Generation for Language\nLearning Items. In Proceedings of the 2022 Confer-\nence on Empirical Methods in Natural Language Pro-\ncessing: Industry Track, pages 294\u2013305, Abu Dhabi,\nUAE. Association for Computational Linguistics.\nAna\u00efs Tack and Chris Piech. 2022. The AI Teacher Test:\nMeasuring the Pedagogical Ability of Blender and\nGPT-3 in Educational Dialogues. In Proceedings of\nthe 15th International Conference on Educational\nData Mining, page 522.\nRohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann\nDubois, Xuechen Li, Carlos Guestrin, Percy Liang,\nand Tatsunori B Hashimoto. 2023. Alpaca: A\nStrong, Replicable Instruction-Following Model.\nStanford Center for Research on Foundation Models.\nhttps://crfm. stanford. edu/2023/03/13/alpaca. html,\n3(6):7.\nHugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier\nMartinet, Marie-Anne Lachaux, Timoth\u00e9e Lacroix,\nBaptiste Rozi\u00e8re, Naman Goyal, Eric Hambro, Faisal\nAzhar, et al. 2023a. LLaMA: Open and Effi-\ncient Foundation Language Models. arXiv preprint\narXiv:2302.13971.\nHugo Touvron, Louis Martin, Kevin Stone, Peter Al-\nbert, Amjad Almahairi, Yasmine Babaei, Nikolay\nBashlykov, Soumya Batra, Prajjwal Bhargava, Shruti\nBhosale, et al. 2023b. Llama 2: Open Founda-\ntion and Fine-Tuned Chat Models. arXiv preprint\narXiv:2307.09288.\nSowmya Vajjala and Taraka Rama. 2018. Experiments\nwith Universal CEFR Classification. In Proceedings\nof the Thirteenth Workshop on Innovative Use of\nNLP for Building Educational Applications , pages\n147\u2013153, New Orleans, Louisiana. Association for\nComputational Linguistics.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3257, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "701b18cc-e46a-4173-9dbd-ae51764b94d9": {"__data__": {"id_": "701b18cc-e46a-4173-9dbd-ae51764b94d9", "embedding": null, "metadata": {"page_label": "12", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "40542742-aec1-423e-8af1-02002e279650", "node_type": "4", "metadata": {"page_label": "12", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "hash": "fd1cdf2318c8ed31afa3d475a59e79ee5a0e4b44d8b6a2d040fcc25505917c89", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5059f07b-53fc-4c41-b737-4e7bc32ea580", "node_type": "1", "metadata": {"page_label": "12", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "hash": "83fcf20e8a98ee3f13413b65492c3e09c8a2403018393e9c425519927831b859", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "arXiv preprint\narXiv:2302.13971.\nHugo Touvron, Louis Martin, Kevin Stone, Peter Al-\nbert, Amjad Almahairi, Yasmine Babaei, Nikolay\nBashlykov, Soumya Batra, Prajjwal Bhargava, Shruti\nBhosale, et al. 2023b. Llama 2: Open Founda-\ntion and Fine-Tuned Chat Models. arXiv preprint\narXiv:2307.09288.\nSowmya Vajjala and Taraka Rama. 2018. Experiments\nwith Universal CEFR Classification. In Proceedings\nof the Thirteenth Workshop on Innovative Use of\nNLP for Building Educational Applications , pages\n147\u2013153, New Orleans, Louisiana. Association for\nComputational Linguistics.\nGuan Wang, Sijie Cheng, Xianyuan Zhan, Xiangang\nLi, Sen Song, and Yang Liu. 2023. OpenChat: Ad-\nvancing Open-source Language Models with Mixed-\nQuality Dataa. arXiv preprint arXiv:2309.11235.\nYizhong Wang, Swaroop Mishra, Pegah Alipoormo-\nlabashi, Yeganeh Kordi, Amirreza Mirzaei, Atharva\nNaik, Arjun Ashok, Arut Selvan Dhanasekaran,\nAnjana Arunkumar, David Stap, Eshaan Pathak,\nGiannis Karamanolakis, Haizhi Lai, Ishan Puro-\nhit, Ishani Mondal, Jacob Anderson, Kirby Kuznia,\nKrima Doshi, Kuntal Kumar Pal, Maitreya Patel,\nMehrad Moradshahi, Mihir Parmar, Mirali Purohit,\nNeeraj Varshney, Phani Rohitha Kaza, Pulkit Verma,\nRavsehaj Singh Puri, Rushang Karia, Savan Doshi,\nShailaja Keyur Sampat, Siddhartha Mishra, Sujan\nReddy A, Sumanta Patro, Tanay Dixit, and Xudong\nShen. 2022. Super-NaturalInstructions: Generaliza-\ntion via declarative instructions on 1600+ NLP tasks.\nIn Proceedings of the 2022 Conference on Empiri-\ncal Methods in Natural Language Processing, pages\n5085\u20135109, Abu Dhabi, United Arab Emirates. As-\nsociation for Computational Linguistics.\nJason Wei, Maarten Bosma, Vincent Zhao, Kelvin Guu,\nAdams Wei Yu, Brian Lester, Nan Du, Andrew M\nDai, and Quoc V Le. 2021. Finetuned Language\nModels are Zero-Shot Learners. In International\nConference on Learning Representations.\nJeromie Whalen, Chrystalla Mouza, et al. 2023. Chat-\nGPT: Challenges, Opportunities, and Implications\nfor Teacher Education. Contemporary Issues in Tech-\nnology and Teacher Education, 23(1):1\u201323.\nMenglin Xia, Ekaterina Kochmar, and Ted Briscoe.\n2016. Text Readability Assessment for Second Lan-\nguage Learners. In Proceedings of the 11th Workshop\non Innovative Use of NLP for Building Educational\nApplications, pages 12\u201322, San Diego, CA. Associa-\ntion for Computational Linguistics.\nSusan Zhang, Stephen Roller, Naman Goyal, Mikel\nArtetxe, Moya Chen, Shuohui Chen, Christopher De-\nwan, Mona Diab, Xian Li, Xi Victoria Lin, et al.\n2022. OPT: Open Pre-trained Transformer Language\nModels. arXiv preprint arXiv:2205.01068.", "mimetype": "text/plain", "start_char_idx": 2690, "end_char_idx": 5269, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "2ac26ec6-8e2d-4c38-b372-87a3fbaddecb": {"__data__": {"id_": "2ac26ec6-8e2d-4c38-b372-87a3fbaddecb", "embedding": null, "metadata": {"page_label": "13", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "43dbd250-fa5f-4d20-89ff-57fb0fddffb5", "node_type": "4", "metadata": {"page_label": "13", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "hash": "cb146cc98eacede93d14605ddffef50821364bf92237e342cbbbb58d0d331d83", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Wangchunshu Zhou, Yuchen Eleanor Jiang, Ethan\nWilcox, Ryan Cotterell, and Mrinmaya Sachan. 2023.\nControlled text generation with natural language in-\nstructions. In Proceedings of the 40th International\nConference on Machine Learning , volume 202 of\nProceedings of Machine Learning Research, pages\n42602\u201342613. PMLR.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 316, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "a00703fd-9a48-486a-90ec-27c62200f4a6": {"__data__": {"id_": "a00703fd-9a48-486a-90ec-27c62200f4a6", "embedding": null, "metadata": {"page_label": "14", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "ac1c7c2f-6976-4682-b5ed-b44f89aaa87e", "node_type": "4", "metadata": {"page_label": "14", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "hash": "000c3a801535dae464ee1d4f6af194ad2dea4f03fa2abc1c0d4d1f1f64c8b325", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "4128dbbd-104d-4975-a7d6-4a645bbd0614", "node_type": "1", "metadata": {}, "hash": "c202f7ad2e1a5315d95407307a1c2308bd1d38064954454b314526212270c502", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "A Appendix\nA.1 Libraries and Dependencies\nWe have used the following dependencies and\nPython libraries for the study: Linguistic Fea-\nture Tool Kit (LFTK) (Lee and Lee, 2023), Spacy\n(https://spacy.io/), Scikit-Learn (https:\n//scikit-learn.org/stable/ ), OpenAI\nAPI (https://openai.com/blog/open\nai-api).\nA.2 Corpus Statistics\nWe provide basic statistical information about the\nvarious corpora used in the study.\nLevel Size Average\nWord Count\nAverage\nSentence Count\nA2 60 186.55 18.91\nB1 60 264.25 15.90\nB2 60 517.71 31.71\nC1 60 728.93 40.70\nC2 60 749.73 37.55\nTable 4: Statistics of the ELG corpus (Breuker, 2022)\nused for the CEFR context assisted story generation\ntask.\nGrade Size Average\nWord Count\nAverage\nSentence Count\nElementary 48 204.91 28.55\nAdvanced 73 255.17 31.08\nTable 5: Statistics of the official CCS -aligned corpus\n(Flor et al., 2013) used as gold-standard dataset for the\nSTANDARDIZE -L artifact and for training the CCS clas-\nsifier used in Section 7.\nLevel Size Average\nWord Count\nAverage\nSentence Count\nA2 64 60.87 11.53\nB1 60 122.38 16.25\nB2 71 265.35 37.03\nC1 67 355.71 43.37\nC2 69 333.86 38.41\nTable 6: Statistics of the Cambridge Exams corpus (Xia\net al., 2016) used as gold-standard dataset for the STAN-\nDARDIZE -L artifact and for training the CEFR classifier\nused in Section 7.\nA.3 Additional Information on Models and\nInference\nWe set the minimum generated new tokens to 30\nand the maximum to 300, as well as set the nucleus\nsampling decoding (top-p) to 0.95 as done with\nprevious works on story generation (Imperial and\nMadabushi, 2023; DeLucia et al., 2021; See et al.,\n2019). The actual sizes of the open models range\nfrom 5GB to 15 GB max. We used a hosted GPU\ncloud with 4 NVIDIA Ti 3090 with 24GB memory\nsize for model inference.\nLlama2-Chat (Touvron et al., 2023b) is one of\nthe community-recognized open instruction-tuned\nmodels released by Meta and an improved version\nof Llama 1 (Touvron et al., 2023a). For this task,\nwe use the 7B version 9 finetuned from over a\nmillion human preference data and optimized\nfor chat and dialogue use cases. We prioritized\nthe addition of this model in our study for its\naccessibility to the general NLP community.\nLongform-OPT (K\u00f6ksal et al., 2023) is a recent\ninstruction-tuned model optimized for long text\ngeneration using the LongForm dataset. For this\nstudy, we use the OPT model variant 10 (Zhang\net al., 2022) with 2.7B parameters as this version\nobtained the best performance for the short story\ngeneration task using the WRITING PROMPTS\ndataset (Fan et al., 2018) against other instruction-\ntuned models such as Alpaca-LLaMA (Taori et al.,\n2023), FlanT5 (Chung et al., 2022), Tk-Instruct\n(Wang et al., 2022), and T0++ (Sanh et al., 2021).\nOpenChat (Wang et al., 2023) is the most recent\nopen model in our experiment setup, which\ncurrently is reported to be the best 7B model as\nof this writing and outperforms closed models\nsuch as ChatGPT (March) across a number of\nbenchmark tasks such as GSM8K and TruthfulQA.\nIn contrast to Llama and GPT models, which used\nRLHF (Ouyang et al., 2022), OpenChat is trained\nwith mixed-quality data which is composed of\nhigh-quality expert data and sub-optimal web data\nwith no preference labels.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3215, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "4128dbbd-104d-4975-a7d6-4a645bbd0614": {"__data__": {"id_": "4128dbbd-104d-4975-a7d6-4a645bbd0614", "embedding": null, "metadata": {"page_label": "14", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "ac1c7c2f-6976-4682-b5ed-b44f89aaa87e", "node_type": "4", "metadata": {"page_label": "14", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "hash": "000c3a801535dae464ee1d4f6af194ad2dea4f03fa2abc1c0d4d1f1f64c8b325", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "a00703fd-9a48-486a-90ec-27c62200f4a6", "node_type": "1", "metadata": {"page_label": "14", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "hash": "df0a7ab936d584c4536e5432bbe2b5567d14c52bd2ed436bd34db49ad84c8b01", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "OpenChat (Wang et al., 2023) is the most recent\nopen model in our experiment setup, which\ncurrently is reported to be the best 7B model as\nof this writing and outperforms closed models\nsuch as ChatGPT (March) across a number of\nbenchmark tasks such as GSM8K and TruthfulQA.\nIn contrast to Llama and GPT models, which used\nRLHF (Ouyang et al., 2022), OpenChat is trained\nwith mixed-quality data which is composed of\nhigh-quality expert data and sub-optimal web data\nwith no preference labels. We use the 7B version11\nof this model variant released in January 2024.\nGPT-4 (OpenAI, 2023) is the only closed model in-\ncluded in this study. We decide to add this model to\nour experiment for its global recognition through its\n9https://huggingface.co/meta-llama/Lla\nma-2-7b-chat-hf\n10https://huggingface.co/akoksal/LongF\norm-OPT-2.7B\n11https://huggingface.co/openchat/open\nchat-3.5-0106", "mimetype": "text/plain", "start_char_idx": 2724, "end_char_idx": 3604, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "4c267a67-44fb-4d51-a988-2471b5ec8d26": {"__data__": {"id_": "4c267a67-44fb-4d51-a988-2471b5ec8d26", "embedding": null, "metadata": {"page_label": "15", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "4bd10bab-517e-4412-aa4b-1833db2779d7", "node_type": "4", "metadata": {"page_label": "15", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "hash": "a918d8795213107875bd9a25949297e26105f8a731a96048e77908376b27c2e8", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "easy-to-use interface among interdisciplinary fields,\nparticularly in education (Kasneci et al., 2023). We\nuse the version12 finetuned with proprietary train-\ning data up to April 2023 with a 128K context\nwindow.\nA.4 Exemplars List\nWe list the actual list of literary exemplars used\nfor the STANDARDIZE framework. We manually\nselected at most three classical exemplars as refer-\nence for the language models.\nLevel Exemplars\nA2 A Christmas Carol by Charles Dickens\nThe Adventures Of Huckleberry Finn by Mark Twain\nThe Little Prince by Antoine de Saint-Exupery\nB1 Frankenstein by Mary Shelley\nWuthering Heights by Emily Bronte\nMidsummer Night\u2019s Dream by Shakespeare\nB2 Moby Dick by Herman Melville\nJane Eyre by Charlotte Bronte\nSense and Sensibility by Jane Austen\nC1 Animal Farm by George Orwell\nAnna Karenina by Leo Tolstoy\nGreat Expectations by Charles Dickens\nC2 Oliver Twist by Charles Dickens\nCrime and Punishment by Fyodor Dostoevsky\nLes Miserables by Victor Hugo\nTable 7: The full exemplar list used for CEFR standards\nobtained from the Penguin Reader website ( https:\n//www.penguinreaders.co.uk/).\nGrade Exemplars\nElementary Little Women by Louisa May Alcott\nThe Adventures of Tom Sawyer by Mark Twain\nThe Road Not Taken by Robert Frost\nAdvanced Jane Eyre by Charlotte Bront\u00eb\nThe Great Gatsby by F. Scott Fitzgerald\nFahrenheit 451 by Ray Bradbury\nTable 8: The full exemplar list used for CCS standards\nobtained from the official website ( https://www.\nthecorestandards.org/ELA-Literacy/).\nA.5 Mean Values of Linguistic Flags\nWe provide the computed averages of the linguistic\nflags from the aspects of the two standards, CEFR\nand CCS, used in this work reported in Tables 10\nand 11.\n12https://platform.openai.com/docs/mod\nels/gpt-4-and-gpt-4-turbo\nA.6 Additional Information on Human\nExpert Evaluation\nWe created and distributed the evaluation instru-\nment through QuestionPro (https://www.qu\nestionpro.com/ ). In contrast to non-expert\nvalidation techniques where all instances are dis-\ntributed automatically to available annotator plat-\nforms such as Amazon Turk, we use a represen-\ntative random sample of our data for evaluation\nin consideration with the experts\u2019 time constraints.\nFor all tests, we randomly sampled 10% of the\ntotal generated narrative content using the best-\nperforming model, which is both the GPT-4 model\nwith STANDARDIZE -\u22c6, for each corresponding task\nassociated with CEFR and CCS as described in\nSection 6.\nFor grammaticality and coherence evaluation,\nwe adapted the same four-point Likert scale from\nthe work of DeLucia et al. (2021) for evaluating\nselect model-generated content found through this\nlink: https://github.com/JHU-CLSP/\ngpt2-narrative-decoding/ . Snapshots\nof the instruction and test instances presented to\nexperts for evaluation can be viewed in Figures 10\nand 11.\nFor the grade complexity distinction, we adapted\na simpler select-one response type where for each\ntest instance being evaluated, we select a random\ntest instance from the adjacent next level of the\ntarget test instance and ask the experts to select\nwhich two examples of model-generated content\nare more simpler or complex. The idea here is that\nthe expert should be able to tell the obviousness of\nthe complexity of the test instance by indicating\nwhich is simpler or more complex. Snapshots of the\ninstruction and test instances presented to experts\nfor evaluation can be viewed in Figures 12 and 13.\nOverall, our human evaluation design has been\nvalidated by the experts in language assessment we\ncollaborated with through preliminary discussions\non the scope, instrument, target outcomes, and pre-\nsentation of the results from the task. As a form\nof compensation, we offered \u00a330 upon completion\nof the entire task, which the experts took about ap-\nproximately 30 \u221245 minutes. The experts will also\nbe acknowledged in this paper upon publication.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3870, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "a9bb14cd-c0cf-4a9d-8ba0-150893151cef": {"__data__": {"id_": "a9bb14cd-c0cf-4a9d-8ba0-150893151cef", "embedding": null, "metadata": {"page_label": "16", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "eeb7a7ba-2dbe-4411-b51b-709b06b24fb3", "node_type": "4", "metadata": {"page_label": "16", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "hash": "fdba2d0117a668f36388eefdf6519271474e7e25d880d2804157464f924fac52", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "A2 B1 B2 C1 C2\n2.5\n5.0\n7.5\n10.0\n12.5\n15.0\n17.5\n20.0 T eacher-Style\nStandardize\nGrade 4 - 8 Grade 9 - 12\n0\n2\n4\n6\n8\n10\n12\nT eacher-Style\nStandardize\nFigure 6: Distribution of average sentence length between CEFR using (left) and CCS (right) using their best\nperforming models, GPT-4 and Llama2, with STANDARDIZE -L.\nA2 B1 B2 C1 C2\n0.0\n0.5\n1.0\n1.5\n2.0 T eacher-Style\nStandardize\nGrade 4 - 8 Grade 9 - 12\n0.00\n0.25\n0.50\n0.75\n1.00\n1.25\n1.50\n1.75 T eacher-Style\nStandardize\nFigure 7: Distribution of average entity density between CEFR using (left) and CCS (right) using their best\nperforming models, GPT-4 and Llama2, with STANDARDIZE -L.\nA2 B1 B2 C1 C2\n4\n6\n8\n10\n12\n14 T eacher-Style\nStandardize\nGrade 4 - 8 Grade 9 - 12\n2\n4\n6\n8\n10\nT eacher-Style\nStandardize\nFigure 8: Distribution of type token ratio between CEFR using (left) and CCS (right) using their best performing\nmodels, GPT-4 and Llama2, with STANDARDIZE -L.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 913, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "75ca7693-3a68-4df5-b37d-bf56c8075bce": {"__data__": {"id_": "75ca7693-3a68-4df5-b37d-bf56c8075bce", "embedding": null, "metadata": {"page_label": "17", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "faa5cfee-2267-4927-9d57-0d993ce6ac9e", "node_type": "4", "metadata": {"page_label": "17", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "hash": "33bfd604654ad59d513bcec7a13cef1f82200974f66c03311e3b6d6d189268c7", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c83fe11c-cf03-4966-911c-ec6d6050ba2b", "node_type": "1", "metadata": {}, "hash": "9450209fc78519785dd2652b4a67c384737f32047abd1749c1213d474cb7d350", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Level Meaning and Purpose Organisation and Stucture Grammatical Complexity\nA2 The text is clear and concrete, aiming to describe\nappearance, places, routines, preferences, or tell a\nsimple story.\nThe text is often short and observes\nchronological and predictable structure.\nThe text contains comparison of adjectives, rel-\native clauses, quantifiers, past simple of to be\nand full verbs, passive voice of present and\npast simple.\nB1 The text is clear and concrete, aiming to describe\nappearance, places, routines, preferences, or tell a\nsimple story. The text may also provide opinions\nand instructions or explanations, easy to understand\nand visualise, excluding ambiguity and diverse in-\nterpretations.\nThe text can be long but not complex, and\nobserves mostly chronological with unex-\npected changes of direction, digressions\nor flashbacks.\nThe text contains future forms, future in the\npast, \u2019used to\u2019 about repeated actions, present\nperfect simple, clauses for purpose and con-\ntrast, reporting statements, tag questions.\nB2 The text provides opinions and instruc-\ntions/explanations, easy to understand and\nvisualise, excluding ambiguity and diverse in-\nterpretations. The text also gives description,\nclassification, argumentation or a combination\nof these, allowing greater ambiguity and various\ninterpretations.\nThe text can be long but not complex, and\nobserves chronological or spatial with\npossible statement of various aspects of a\nphenomenon.\nThe text contains past continuous, past per-\nfect, passive voice of perfect and continuous,\n\u2019would\u2019 about habits, reporting questions, in-\nfinitives and -ing forms.\nC1 The text may serve different purposes and may be\ncombined with multiple levels of meaning. The\ndescriptions and instructions in the text are detailed\nand may be hard to visualise.\nThe text is often lengthy, complex, and\nobserves logical organisation, starting\nwith a claim followed by reasons, proving\nit, or changing view-points.\nThe text contains compound adjectives, condi-\ntional sentences, inversion, future perfect, cleft\nand non-finite clauses, modals about the past.\nC2 The text may serve different purposes and may be\ncombined with multiple levels of meaning. The text\nmay also show exploration of hypotheses, causes\nand effects, etc. The details of the text are complex\nto follow and visualise.\nThe text is often lengthy, complex, and\nobserves presentation which may start\nwith the ending/final result and go back\nto the possible causes.\nThe text contains combination of multiple ad-\njectives, inversion with hardly and only when,\ncomment clauses, non-finite perfect clauses,\nellipsis, passive impersonal constructions.\nLinguistic\nFlags\nAutomatic Readability Formula, Type Token Ratio\n(2)\nTotal and average sentence and word\nlengths, Subordinating and coordinating\nconjunctions (4)\nAge-of-Acquisition and USubtlex densities,\nentity density per sentence (3)\n(a) The specifications provided by the Common European Framework of Reference for Languages (CEFR) cover aspects of\nmeaning, organization, and grammatical complexity for all levels.\nAspects Qualitative (Meaning) Qualitative (Syntax) Quantitative (Length)\nDescription The text can range from containing a sin-\ngle level of meaning to multiple levels of\nmeaning based on complexity.\nA text with low complexity tends to have simple,\nwell-marked, and conventional structures, whereas\na text of high complexity tends to have complex, im-\nplicit, and unconventional structures. Simple texts\ntend to relate events in chronological order, while\ncomplex texts make more frequent use of flashbacks,\nflash-forwards, and other manipulations of time and\nsequence.\nThat text that has longer words and longer\nsentences are more difficult to read than\nshorter ones. A text with many long\nwords and/or sentences is thus rated by\nthese formulas as harder to read than a\ntext with many short words and/or sen-\ntences would be.\nLinguistic\nFlags\nEntity densities per sentence, Total proper\nnoun density (2)\nType Token Ratio, Subordinating and coordinating\nconjunctions (3)\nTotal and average sentence and word\nlengths (3)\n(b) The specifications of the Common Core Standards (CCS) cover qualitative and quantitative aspects. Unlike the CEFR, the\nCCS\u2019s model does not require categorization per level.\nTable 9: The full content of the CEFR and CCS standards with corresponding manually selected representative\nlinguistic flags for each aspect.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4411, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c83fe11c-cf03-4966-911c-ec6d6050ba2b": {"__data__": {"id_": "c83fe11c-cf03-4966-911c-ec6d6050ba2b", "embedding": null, "metadata": {"page_label": "17", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "faa5cfee-2267-4927-9d57-0d993ce6ac9e", "node_type": "4", "metadata": {"page_label": "17", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "hash": "33bfd604654ad59d513bcec7a13cef1f82200974f66c03311e3b6d6d189268c7", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "75ca7693-3a68-4df5-b37d-bf56c8075bce", "node_type": "1", "metadata": {"page_label": "17", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "hash": "5d1ad8797dec95ebe592fff0c4b9e4dd1471fd9b8975480b9930f2f24f53793c", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "That text that has longer words and longer\nsentences are more difficult to read than\nshorter ones. A text with many long\nwords and/or sentences is thus rated by\nthese formulas as harder to read than a\ntext with many short words and/or sen-\ntences would be.\nLinguistic\nFlags\nEntity densities per sentence, Total proper\nnoun density (2)\nType Token Ratio, Subordinating and coordinating\nconjunctions (3)\nTotal and average sentence and word\nlengths (3)\n(b) The specifications of the Common Core Standards (CCS) cover qualitative and quantitative aspects. Unlike the CEFR, the\nCCS\u2019s model does not require categorization per level.\nTable 9: The full content of the CEFR and CCS standards with corresponding manually selected representative\nlinguistic flags for each aspect.\nAspect Linguistic Flag A2 B1 B2 C1 C2\nMeaning and Purpose\naverage_entities_per_sentence 0.92 0.93 0.68 0.7 0.5\naverage_AoA_per_sentence 51.4 76.7 82.6 94.4 109.9\naverage_USubtlex_per_sentence 69.7 93.1 95.5 101.2 115.8\nOrganization and Structure\ntotal_word_count 60.8 122.3 265.3 355.7 333.8\ntotal_sentence_count 11.5 16.2 37.0 43.3 38.4\naverage_sentence_length 5.3 7.5 7.4 8.7 9.3\ntotal_conjunctions_count 3.6 5.3 11.2 11.9 13.0\nGrammaticality Complexity ARI_formula_readability 7.1 10.6 11.2 13.4 14.4\ncorrelated_type_token_ratio 7.8 9.5 12.1 13.2 13.5\nTable 10: The average values of linguistic flags for each level in the CEFR standard.", "mimetype": "text/plain", "start_char_idx": 3643, "end_char_idx": 5052, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e2f6369c-7916-492c-8d0f-719f67737d65": {"__data__": {"id_": "e2f6369c-7916-492c-8d0f-719f67737d65", "embedding": null, "metadata": {"page_label": "18", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "e1206ad4-2875-415d-baa2-213c96ae3fe5", "node_type": "4", "metadata": {"page_label": "18", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "hash": "e2ea6b9e97ba882a1cd3fe002ab9d9e808edb502f64dcb98af0c91614b3c16f2", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "ba41b74f-41d8-4e0b-9478-e2ec23c11189", "node_type": "1", "metadata": {}, "hash": "36393c47e14404a9bc73e6c940f162efd4e9a794800d85afdca73c7af48164d2", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Aspect Linguistic Flag Elementary Advanced\nQualitative (Meaning) average_entities_per_sentence 0.6 0.8\naverage_proper_nouns 7.3 15.5\nQualitative (Syntax)\naverage_coordinating_conjunction 2.5 3.1\naverage_subordinating_conjunction 6.5 14.9\ncorrelated_type_token_ratio 9.1 11.4\nQuantitative (Length)\ntotal_word_count 141.2 255.2\ntotal_sentence_count 24.9 31.0\naverage_sentence_length 6.2 9.6\nTable 11: The average values of linguistic flags for each level in the CCS standard.\nTARGET LEVEL : A2 (Elementary / Beginning Reading Level)\nCONTEXT : Corryvale Farm is in the west of England. Stephen and Jenny Blackler keep cows and chickens and sell\nmilk and eggs. But most of their money comes from Jenny\u2019s sheep. She has 50 sheep and each one has enough\nwool for six sweaters. Every six months Stephen cuts this wool off the sheep so they won\u2019t get too warm.\nTEACHER STYLE : In the lush, verdant lands of the west of England, nestled among rolling hills and meandering\nstreams, lay Corryvale Farm. It was a picturesque farm, embodying the pastoral beauty that many dreamt of, yet\nfew had the fortune to call home. This was the realm of Stephen and Jenny Blackler, a couple whose lives were as\nintertwined with the land as the ancient oak roots were with the earth. Stephen, a robust man with hands as rough as\nthe bark of the trees he often climbed, tended to the cows and chickens with a steady patience. He rose with the sun,\ngreeted by the gentle mooing of the cows and the cheerful chaos of the clucking chickens. The rhythm of milking\nthe cows and collecting eggs was a comforting routine that marked the passage of days on the farm.\nSTANDARDIZE -A: At Corryvale Farm, Stephen would wake up early. Even if it was as cold as ice outside, he\nstarted the day with the same routine. First, he would feed the cows. There, in the fields, were 30 healthy cows.\nThese cows were beautiful, larger than any other cows in the west of England. They were the pride of the farm.\nThen, he would go to the chickens. He had roughly 100 chickens that laid the best eggs every morning. The chickens\nwere quite noisy and more excited than the quiet cows, making mornings lively on the farm. Jenny was not a big fan\nof waking up early, she preferred to sleep a bit more. However, her work started after breakfast. Her favourite part\nof the day was when she went to see her sheep. She loved them dearly. She always said that her 50 sheep were the\ncleanest and happiest sheep in the entire country. She was so proud of them.\nSTANDARDIZE -E: Stephen and Jenny loved these days on their Corryvale Farm, filled with the soft clucking of\nchickens and lowing of cows. They took pride in their daily duties of caring for all the animals, especially the sheep\nthat were their main source of income. One cold morning, Jenny took her pail to milk the cows while Stephen\nchecked the hens\u2019 house for fresh eggs. Their cheeks were red from the cool air and they could see their breath\nwhen they talk. But they didn\u2019t mind the chill for the promise of spring was around the corner. Meanwhile, back in\nthe barn, Jenny\u2019s 50 sheep huddled together, their woolly coats growing thicker in the cool weather. This would\nmean only one thing. It was shearing time! Every six months, like clockwork, Stephen would sheer the sheep\u2019s\nwool. For each sheep he could fill a bag with enough wool to knit six sweaters. The wool was not just soft but warm\ntoo, a perfect shield against the bitter winter.\nSTANDARDIZE -L: Corryvale Farm is in the west of England. It is Stephen and Jenny Blackler\u2019s farm. They have\ncows and chickens. They sell milk and eggs. Jenny also has 50 sheep. The sheep have wool. Every six months,\nStephen cuts the wool. This keeps the sheep cool. They make money from the wool.\nSTANDARDIZE -\u22c6: Corryvale Farm is in England\u2019s west. Here, Stephen and Jenny live.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3830, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "ba41b74f-41d8-4e0b-9478-e2ec23c11189": {"__data__": {"id_": "ba41b74f-41d8-4e0b-9478-e2ec23c11189", "embedding": null, "metadata": {"page_label": "18", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "e1206ad4-2875-415d-baa2-213c96ae3fe5", "node_type": "4", "metadata": {"page_label": "18", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "hash": "e2ea6b9e97ba882a1cd3fe002ab9d9e808edb502f64dcb98af0c91614b3c16f2", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e2f6369c-7916-492c-8d0f-719f67737d65", "node_type": "1", "metadata": {"page_label": "18", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "hash": "8f95254c5822cfb9271f129215b5d09a319a8a6bbcb190b1e5a1e50dc4731b2b", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "This would\nmean only one thing. It was shearing time! Every six months, like clockwork, Stephen would sheer the sheep\u2019s\nwool. For each sheep he could fill a bag with enough wool to knit six sweaters. The wool was not just soft but warm\ntoo, a perfect shield against the bitter winter.\nSTANDARDIZE -L: Corryvale Farm is in the west of England. It is Stephen and Jenny Blackler\u2019s farm. They have\ncows and chickens. They sell milk and eggs. Jenny also has 50 sheep. The sheep have wool. Every six months,\nStephen cuts the wool. This keeps the sheep cool. They make money from the wool.\nSTANDARDIZE -\u22c6: Corryvale Farm is in England\u2019s west. Here, Stephen and Jenny live. They have cows, chickens,\nand 50 sheep. The sheep\u2019s wool can make six sweaters each. Every six months, Stephen shears the sheep. This\nkeeps them cool. Jenny\u2019s sheep are very important. They sell milk, eggs, and wool. This is their farm life.\nTable 12: Sample generations with the teacher style method and variations of the STANDARDIZE framework using\nthe best model (GPT-4) for the context-assisted story generation observing CEFR standards. Some examples are\ntruncated for brevity.", "mimetype": "text/plain", "start_char_idx": 3165, "end_char_idx": 4313, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "00bab8de-0746-4592-b9c1-7b6f10eb89ac": {"__data__": {"id_": "00bab8de-0746-4592-b9c1-7b6f10eb89ac", "embedding": null, "metadata": {"page_label": "19", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "0c40234f-5286-4c2c-a086-028a1c41410a", "node_type": "4", "metadata": {"page_label": "19", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "hash": "b79360ba52dabd14df5d980aa9b9d4baf0ca7e77881c92986dd22699e95e31ab", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "TARGET GRADE : Elementary\nTHEME WORD : Curses\nTEACHER STYLE : In the small village of Ashwood, nestled in the heart of the Whispering Woods, a young\napprentice named Eira stumbled upon an ancient tome hidden deep within the village library. The tome was bound\nin black leather and adorned with strange symbols that seemed to shift and writhe like living things. As soon as Eira\nopened the book, a puff of noxious smoke erupted from its pages, filling the air with a pungent stench. The smoke\ncoalesced into a low, menacing whisper that seemed to seep into Eira\u2019s mind. \"Curse you, Eira,\" the voice hissed.\n\"You have disturbed the rest of the ancient ones. Now you will pay the price.\" Eira felt a cold dread creeping up her\nspine as the voice continued to taunt her. \"You have unleashed a power beyond your control. Prepare to face the\nconsequences.\"\nSTANDARDIZE -A: Once upon a time, in a small town nestled in the heart of a dense forest, there stood a grand\nmansion rumored to be haunted. The mansion had been abandoned for decades, its grandeur and beauty slowly\nbeing consumed by the encroaching trees and vines. The locals avoided the mansion, whispering tales of curses\nand ghostly apparitions that roamed its halls. One summer evening, a group of curious children stumbled upon the\nmansion while exploring the woods. They cautiously approached the mansion, their hearts racing with every creak\nand groan of the old wooden doors.\nSTANDARDIZE -E: Once upon a time, in a small town nestled in the heart of a dense forest, there stood a grand\nmansion that had been abandoned for decades. The mansion was rumored to be haunted by the ghosts of its former\nowners, who had died under mysterious circumstances. The townspeople whispered stories of strange occurrences\nthat had taken place within the mansion\u2019s walls. Some claimed to have seen ghostly apparitions flitting about in\nthe windows at night, while others swore they had heard eerie whispers emanating from the abandoned halls. One\nstormy evening, a group of brave adventurers decided to explore the cursed mansion, determined to uncover its\nsecrets. As they approached the entrance, the wind howled and the trees creaked ominously, as if warning them\naway.\nSTANDARDIZE -L: In the small town of Willow Creek, there stood a grand mansion that had been abandoned for\ndecades. The once-grand estate was now a relic of the past, its grandeur faded and its windows shattered. The\nlocals whispered stories of the mansion\u2019s dark history, how it was cursed by a witch who had lived there many years\nago. According to the legend, the witch had been wronged by the mansion\u2019s owner, who had refused to grant her a\nsimple wish. Enraged, the witch placed a curse on the mansion, ensuring that no one would ever be able to live there\npeacefully. The curse was said to cause strange occurrences and unexplained noises to echo through the empty halls,\nmaking it impossible for anyone to enter or leave the mansion without experiencing terrifying events. One stormy\nnight, a group of brave adventurers decided to investigate the rumors and put an end to the curse. They entered the\nmansion, their flashlights casting eerie shadows on the walls. As they explored the dusty rooms, they began to hear\nstrange noises, like whispers in the darkness.\nSTANDARDIZE -\u22c6: In a small town that lay in the shadow of a dark, dense forest, there was a tale that had been\npassed down for generations. The tale was of three witches who lived deep within the woods, guarding a secret that\ngave them immense power. Children would listen with wide eyes as their parents told the story on stormy nights, the\nwind howling outside as if the witches themselves were listening. The eldest witch, Morgana, could talk to animals\nand control the weather with a wave of her hand. The second, Elspeth, brewed potions that could heal any illness\nor curse one with a single sip. The youngest, Seraphina, had the gift of foresight, able to see events before they\nunfolded.\nTable 13: Sample generations with the teacher style method and variations of the STANDARDIZE framework using\nthe best model (Llama2) for the theme word story generation observing CCS standards. Some examples are\ntruncated for brevity.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4217, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "075e0013-e8a1-4152-b202-9a6358d40994": {"__data__": {"id_": "075e0013-e8a1-4152-b202-9a6358d40994", "embedding": null, "metadata": {"page_label": "20", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "09df8e14-4af3-4ef0-ad85-eddbe3b7a241", "node_type": "4", "metadata": {"page_label": "20", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "hash": "ffb2920c5f3a944e6b0eb642ccb7aefdc8cbfd4369c68f9267b982377d3da94a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Figure 9: Landing page of the QuestionPro platform used for collecting expert evaluations.\nFigure 10: Instructions presented to expert evaluators for assessing the grammaticality or fluency and coherence of\nmodel-generated content for CEFR and CCS through QuestionPro. The setup is derived from DeLucia et al. (2021).", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 317, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "1e543b19-ce48-4dc2-856e-b98b633dd095": {"__data__": {"id_": "1e543b19-ce48-4dc2-856e-b98b633dd095", "embedding": null, "metadata": {"page_label": "21", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2b14664e-9550-428b-99f3-1e33ff83ad8d", "node_type": "4", "metadata": {"page_label": "21", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "hash": "6e8e7a9dd7aa4705802f923fcd234e84b0052ea1e6d61561bcad9ba0e3b61cb9", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Figure 11: An example of randomly selected generated content presented to expert evaluators to assess grammati-\ncality or fluency and coherence. The example is truncated for brevity.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 182, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c6ad923d-7c21-4a7d-9087-042f11e03352": {"__data__": {"id_": "c6ad923d-7c21-4a7d-9087-042f11e03352", "embedding": null, "metadata": {"page_label": "22", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "c314c64c-400b-4167-9013-34f363ed9e1b", "node_type": "4", "metadata": {"page_label": "22", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "hash": "8743576078c239e09d9297eef61a074696bd372c9ffa11258e22771b087e88e3", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Figure 12: Instructions presented to expert evaluators for assessing the grade complexity distinction of model-\ngenerated content for CEFR and CCS through QuestionPro.\nFigure 13: An example of two instances of generated content presented to expert evaluators to assess which one\nis more simpler or more complex denoting obviousness in their grade complexity. The example is truncated for\nbrevity.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 396, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f1c3926c-4533-45ca-bd3d-012f6f72eb96": {"__data__": {"id_": "f1c3926c-4533-45ca-bd3d-012f6f72eb96", "embedding": null, "metadata": {"page_label": "1", "file_name": "2405.07354v1.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2405.07354v1.pdf", "file_type": "application/pdf", "file_size": 38960451, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "40b6fc40-dfdf-4ffd-90ab-f004e35f3c3e", "node_type": "4", "metadata": {"page_label": "1", "file_name": "2405.07354v1.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2405.07354v1.pdf", "file_type": "application/pdf", "file_size": 38960451, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "hash": "7c8fbe2cb5af53bc0c7b1c113bef81190fbcf904954a715587e1a140a76509eb", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "SoccerNet-Echoes: A Soccer Game Audio\nCommentary Dataset\nSushant Gautam1,2 Mehdi Houshmand Sarkhoosh2,3 Jan Held5 Cise Midoglu1,3\nAnthony Cioppa5,6 Silvio Giancola6 Vajira Thambawita1\nMichael A. Riegler1 P\u00e5l Halvorsen1,2,3 Mubarak Shah4\n1SimulaMet, Norway 2OsloMet, Norway 3Forzasys, Norway\n4University of Central Florida, USA5University of Li\u00e8ge, Belgium 6KAUST, Saudi Arabia\nhttps://github.com/SoccerNet/sn-echoes\nAbstract\nThe application of Automatic Speech Recognition (ASR) technology in soccer\noffers numerous opportunities for sports analytics. Specifically, extracting audio\ncommentaries with ASR provides valuable insights into the events of the game,\nand opens the door to several downstream applications such as automatic highlight\ngeneration. This paper presents SoccerNet-Echoes, an augmentation of the Soc-\ncerNet dataset with automatically generated transcriptions of audio commentaries\nfrom soccer game broadcasts, enhancing video content with rich layers of textual\ninformation derived from the game audio using ASR. These textual commentaries,\ngenerated using the Whisper model and translated with Google Translate, extend\nthe usefulness of the SoccerNet dataset in diverse applications such as enhanced\naction spotting, automatic caption generation, and game summarization. By incor-\nporating textual data alongside visual and auditory content, SoccerNet-Echoes aims\nto serve as a comprehensive resource for the development of algorithms special-\nized in capturing the dynamics of soccer games. We detail the methods involved\nin the curation of this dataset and the integration of ASR. We also highlight the\nimplications of a multimodal approach in sports analytics, and how the enriched\ndataset can support diverse applications, thus broadening the scope of research and\ndevelopment in the field of sports analytics.\n1 Introduction\nFigure 1: The pipeline for generating a multilingual commentary dataset from soccer game videos,\nincorporating different Whisper versions, language detection and translation.\nSports analytics has progressively embraced technological innovations, to enrich the analysis and\nunderstanding of complex sports events. Historically, analysis of sports video footage relied primarily\non visual cues: action spotting, player recognition and player tracking were based solely on videos\nand video frames as images. However, with the advancement in multimodal data integration, the\narXiv:2405.07354v1  [cs.SD]  12 May 2024", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2463, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "fc2a91b9-e628-44a4-9982-c7a65749f6b9": {"__data__": {"id_": "fc2a91b9-e628-44a4-9982-c7a65749f6b9", "embedding": null, "metadata": {"page_label": "2", "file_name": "2405.07354v1.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2405.07354v1.pdf", "file_type": "application/pdf", "file_size": 38960451, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "f2dfa0c2-590f-4686-ae13-dfbf384308b8", "node_type": "4", "metadata": {"page_label": "2", "file_name": "2405.07354v1.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2405.07354v1.pdf", "file_type": "application/pdf", "file_size": 38960451, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "hash": "faf18660473b57bad62dcc619a33bb31c4ec77264e1c51c4ecd7600735e0073a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "scope of sports analytics has broadened, encompassing audio and textual data alongside traditional\nvisual input. This integration facilitates a more holistic view of sports events, capturing the nuances\nof game dynamics that visual data alone might miss.\nThe SoccerNet dataset [ 12, 7], initially designed to support video-based analyses such as action\nspotting, player tracking [5], camera calibration [4], dense video captioning [24], foul recognition [14,\n15], and game state reconstruction [31], has emerged as a key resource in sports video analytics. Yet,\nthe rapidly evolving field of sports analytics demands ever more sophisticated tools that can process\nand interpret the complex interplay of multiple data modalities, including video, audio, and text.\nIn response to this need, we augment the SoccerNet dataset by incorporating state-of-the-art ASR\ntechnology to enrich the dataset with textual information derived from live game commentaries. This\nmultimodal approach aims to refine the accuracy of existing tasks such as action spotting and dense\nvideo captioning, as well as extends the dataset\u2019s usefulness in more complex applications such as\nsentiment analysis or tactical assessment.\nThis paper details our augmentation of the SoccerNet dataset to include audio commentary transcrip-\ntions, generated with OpenAI\u2019s Whisper [25] tool, and translated with Google Translate [13]. The\nresulting SoccerNet-Echoes dataset serves as a comprehensive toolkit for researchers and practition-\ners, allowing enhanced interpretation and narrative generation from sports footage. Through the\nintegration of audio commentaries in textual format, SoccerNet-Echoes facilitates a deeper under-\nstanding of the contextual aspects of soccer games, thereby enhancing both the analytical capabilities\nand the viewer\u2019s experience.\nContributions. Our contributions are threefold: (i) We augment the SoccerNet dataset with auto-\nmatically transcribed and translated audio commentaries from soccer game broadcasts in multiple\nlanguages, and present this new dataset (SoccerNet-Echoes) as an open-access resource. (ii) We\nevaluate SoccerNet-Echoes using human-verified ASR from literature and perform quantitative analy-\nsis. (iii) We explore the potential applications of SoccerNet-Echoes in various research areas, and\nhighlight the broader implications of adopting a multimodal approach for sports research in general.\n2 Background and Related Work\nThe integration of ASR technology has significantly advanced the analysis and processing of video\ncontent, impacting sports research [22, 20, 21, 3]. Initially, video understanding focused primarily on\ncomputer vision tasks, such as action recognition and event spotting [32, 33, 29, 2]. Advancements\nin dense video captioning [18] began to explore the generation of captions for temporally localized\nactivities within untrimmed videos, representing a significant departure from the traditional approach\nof generating a single caption for short clips. Further evolution in the field saw the incorporation of\naudio and speech modalities alongside visual data, enhancing video captioning capabilities.\n2.1 Early Applications: Action Recognition and Event Detection\nBefore the integration of ASR, the primary focus in sports video analysis was on visual cues for\ngame action recognition and event detection (spotting) [ 12, 7]. Researchers began to explore the\nuse of multimodal sports data, combining game audio and video streams to improve the accuracy of\naction spotting in soccer videos [1, 34]. These studies marked an early recognition of the potential\nbenefits of incorporating audio data alongside traditional video processing, setting the stage for the\nsubsequent integration of ASR technologies in sports game analysis [9].\n2.2 Transition to Speech and Language Processing\nAs the potential of multimodal analysis became evident, subsequent studies began to integrate more\nsophisticated speech and language processing technologies [10, 11]. Gao et al. [8] utilized ASR to\nsegment and categorize commentary from soccer videos, thereby enhancing key moment extraction\nand highlight generation. This application of ASR for segmenting commentator speech represented\na shift towards leveraging linguistic information to complement visual data. Gautam et al. used\ncaptions, text and commentaries extracted from ASR for game summarization [10], and used audio\nintensity to capture the field excitement [11].\n2", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4451, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "1ba63044-7c24-42ba-ac48-c559265dba83": {"__data__": {"id_": "1ba63044-7c24-42ba-ac48-c559265dba83", "embedding": null, "metadata": {"page_label": "3", "file_name": "2405.07354v1.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2405.07354v1.pdf", "file_type": "application/pdf", "file_size": 38960451, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "1d2bc51b-a218-49fc-89b5-58121dd07020", "node_type": "4", "metadata": {"page_label": "3", "file_name": "2405.07354v1.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2405.07354v1.pdf", "file_type": "application/pdf", "file_size": 38960451, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "hash": "2ad83428afc205016cca649bba7919112fbe8fab4b5d0d8cf27255e0048feb3f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "2.3 Multimodal Dense Video Captioning\nThe application of textual modality in sports video analysis reached a new level with the introduction\nof dense video captioning tasks, as exemplified by the SoccerNet Challenge [ 6]. The SoccerNet-\nCaption dataset [23] leverages rich, timestamped textual commentaries that capture both factual and\nemotional aspects of the game. Aiming to bridge the gap for fans unable to watch soccer games\nlive by providing engaging summaries that mimic the excitement of real-time commentary, this task\ndemonstrated the growing importance of textual modality in creating immersive fan experiences.\nLashin et al. [19] highlighted the transformative potential of integrating ASR alongside video and\naudio data in dense video captioning. Their multimodal approach significantly improved event\ndescription accuracy, emphasizing the vital contextual cues provided by ASR that often elude video-\nonly analyses. By combining visual information with speech data, their method demonstrated\nsubstantial performance enhancements, showcasing the synergistic benefits of leveraging multimodal\ninputs for comprehensive video understanding. Movie Audio Descriptions (MAD) dataset offers a\nnovel benchmark for video-language grounding tasks, by aligning audio descriptions of mainstream\nmovies with video content [30]. The multimodal approach has since been embraced [28], enriching\nthe scope of video captioning and commentary generation [26, 27], and illustrating the transformative\nimpact of ASR technology in video content analysis and processing.\n2.4 Advancements in ASR Technologies\nThe development of LLM-based ASR technologies [36] further accelerated the use of speech recog-\nnition in sports analytics. The GOAL dataset [ 26], derived from SoccerNet videos, comprises 80\nfull-game videos transcribed into raw text using the Azure ASR toolkit, then meticulously curated\nby English-speaking, soccer-knowledgeable annotators. 20 games were selected after quality filter-\ning, and annotation tasks included proofreading, aligning text with video timelines, and annotating\nknowledge entities, ensuring comprehensive linguistic and visual analysis. Ikeda et al. [17] leveraged\nASR alongside Whisper [36] and a speech recognition model trained on the extensive Japanese audio\ncorpus ReazonSpeech [35] to transcribe commentary from 134 Japanese Major League Baseball\n(MLB) highlight videos. To address noise challenges, Whisper transcripts underwent manual labeling,\nwhile ReazonSpeech transcripts were labeled using keyword techniques, thereby improving dataset\nquality and reducing time overheads. These approaches underscore a growing trend in leveraging\nASR technology to create rich datasets for detailed examination of both linguistic and visual elements\nin sports commentary.\n2.5 Broader Applications and Future Directions\nThe integration of ASR technology into soccer video analysis has followed a trajectory from enhancing\nbasic action recognition to enabling sophisticated, multimodal interpretations of complex events.\nThe evolution of this technology has not only improved the analytical capabilities of researchers\nbut has also significantly enhanced the viewing experience for fans worldwide. Beyond soccer, the\nintegration of ASR has also influenced broader video analysis tasks. Hessel et al. [ 16] explored\ncombining ASR and visual features to generate captions for instructional videos, highlighting how\nASR can aid in distinguishing between similar actions through linguistic cues. Sattar et al. [ 27]\nfocused on identifying events in cricket games by combining commentary text obtained from ASR\nwith visual data and cues such as replays, bowler and umpire positions.\nThese applications suggest potential future directions where ASR could be integrated into various\ntypes of content beyond sports, enriching content accessibility and understanding across domains.\nAs ASR technology continues to advance, its applications in video analysis are expected to expand,\nfurther revolutionizing the field and providing deeper insights into the intricate dynamics of media\ncontent. However, it is important to acknowledge that despite the advancements, ASR technology\nis not flawless. Automated capture introduces uncertainty and errors in the ground truth data.\nNonetheless, its cost-effectiveness and scalability make ASR a promising candidate for widespread\nuse.\n3", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4389, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f1912059-1bf8-4476-a6b6-d695974ead07": {"__data__": {"id_": "f1912059-1bf8-4476-a6b6-d695974ead07", "embedding": null, "metadata": {"page_label": "4", "file_name": "2405.07354v1.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2405.07354v1.pdf", "file_type": "application/pdf", "file_size": 38960451, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "3adc0f79-a995-47df-9ae9-275863354e4c", "node_type": "4", "metadata": {"page_label": "4", "file_name": "2405.07354v1.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2405.07354v1.pdf", "file_type": "application/pdf", "file_size": 38960451, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "hash": "27d18dfd6527477186e7f687d4ae5f304ec8f471b211874dcefafd78685d4869", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "3 Dataset Curation\nOur comprehensive approach to curating a multilingual soccer commentary dataset, which includes\nthe automated transcription and translation of commentaries, is illustrated in Figure 1. Below, we\ndetail the curation of the SoccerNet-Echoes using the illustrated methodology.\n3.1 Sources and Collection\nWe used all 1100 game half videos from the SoccerNet [12] dataset. These correspond to 550 games\nfrom 6 different leagues and 4 different seasons, as depicted in Figure 2. The games were narrated live\nby commentators speaking one of 10 different languages. The distribution of the original language\nof the broadcast game audio is provided in Figure 3. We automatically extracted commentaries in\ntextual format following the procedure described below.\nEPL Ligue1 SerieA\nBundesliga\nLaLigaUCL\n0\n20\n40\n60\n80Number of Games\n2014-2015\n2015-2016\n2016-2017\n2019-2020\nFigure 2: Number of games per league and season in the SoccerNet dataset (550 in total).\nEnglishSpanishRussianGermanFrenchTurkish Italian PolishBosnianHungarian\nNot Available\n0\n100\n200\n300 297\n264\n218\n135\n102\n4 4 2 2 2\n70\nCount\nFigure 3: Language distribution of the original broadcast audio for each game half, identified using\nGoogle Translate and the Whisper language detection model (1100 in total).\n4", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1284, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "5c823c8d-56cf-4fbd-909a-aeafc1ef001b": {"__data__": {"id_": "5c823c8d-56cf-4fbd-909a-aeafc1ef001b", "embedding": null, "metadata": {"page_label": "5", "file_name": "2405.07354v1.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2405.07354v1.pdf", "file_type": "application/pdf", "file_size": 38960451, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b25b349c-450e-4ff7-9976-15274259cc14", "node_type": "4", "metadata": {"page_label": "5", "file_name": "2405.07354v1.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2405.07354v1.pdf", "file_type": "application/pdf", "file_size": 38960451, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "hash": "9c7099d29f4146b90b4857182286e425e2e4009adcf0af17fab983d0cdf0e1ce", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "3.2 Transcriptions\nWe used OpenAI\u2019s Whisper large-v1 1, large-v2 2, and large-v3 3 ASR models to transcribe the\ncommentator speech from the game audio into text, with the default parameters provided in the\noriginal GitHub implementation (commit: ba3f3cd) [25]. Initially, the ASR models were used to\nprocess all games regardless of the presence of audible human commentary. By default, Whisper\nmodels recognize the audio language from the first 30 seconds of the input, and assume that the rest\nof the audio is in the same language. It should be noted that the model\u2019s capability to accurately\nidentify entity names (players, teams, stadiums, etc.) is limited. We performed explicit language\ndetection for all games using Whisper-v2, the resulting language distribution is depicted in Figure 3.\nFigure 4 presents an example transcription using Whisper from original game audio in English.\n(a)\n (b)\n (c)\n (d)\n (e)\nAutomatic English Transcription\nFrame a to e: \"Here is Coman. I wonder if the referee\u2019s going to book him for that because that\nlooked like a blatant dive really.\"\nFigure 4: Example transcription using Whisper (original audio in English). Key frames are shown to\nrepresent the corresponding video segment.\nManual validation of videos without commentary. As shown in Figure 3, 70 game half videos in\nthe SoccerNet dataset lack audio commentary and therefore had empty ASR outputs. We manually\ninspected these assets to ensure that they do not in fact contain commentary. Overall, 56 videos\nwere confirmed not to have game audio at all, and 14 videos were confirmed to have game audio but\nwithout commentary (only stadium). The detailed list of videos in the SoccerNet dataset without\naudio commentary is released along with the SoccerNet-Echoes dataset as a spreadsheet.\n3.3 Translations\nWe used the language detection output from Whisper to filter non-English commentaries, and\ntranslate the non-English transcriptions into English using Google Translate [13]. This choice was\nmade due to Google Translate\u2019s accessibility, ease, and comprehensive language support. Google\nTranslate generally provides reliable translations, particularly for common languages and everyday\ncommunication. However, its accuracy can vary depending on factors such as text complexity and\nlinguistic nuances. Figures 5 and 6 present example transcriptions using Whisper and translations to\nEnglish using Google Translate (from original game audio in German and Russian, respectively).\n3.4 Final Public Dataset\nThe SoccerNet-Echoes dataset and relevant code are publicly released on GitHub under https:\n//github.com/SoccerNet/sn-echoes. The dataset is organized as multiple folders under the\nDataset directory, grouped by league, season, and game. Figure 9 presents an overview of the\ndirectory structure. Each ASR JSON file contains the transcribed (and translated where applicable)\ncommentary segments for each game half, organized under the \"segments\" key, with each segment\nidentified by a unique index within the respective half. Every segment records the start and end time\nin seconds, which delineate the temporal boundaries of the commentary, along with the transcribed\n1https://huggingface.co/openai/whisper-large\n2https://huggingface.co/openai/whisper-large-v2\n3https://huggingface.co/openai/whisper-large-v3\n5", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3309, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "67ad840e-5392-463f-8dd8-ad474d9f57b0": {"__data__": {"id_": "67ad840e-5392-463f-8dd8-ad474d9f57b0", "embedding": null, "metadata": {"page_label": "6", "file_name": "2405.07354v1.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2405.07354v1.pdf", "file_type": "application/pdf", "file_size": 38960451, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "778cfc29-bfc7-47c1-9a67-7497f4f466ff", "node_type": "4", "metadata": {"page_label": "6", "file_name": "2405.07354v1.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2405.07354v1.pdf", "file_type": "application/pdf", "file_size": 38960451, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "hash": "6b55c3dcf4f69b3a8b901e6dd34d031173f78909598b22110afb98a75445da56", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "(a)\n (b)\n (c)\n (d)\n (e)\nAutomatic German Transcription and English Translation\nFrame a to e (Transcription): \"Spiel f\u00fcr RB Leipzig, die Mannschaft spielt in wei\u00df und rot\nBorussia Dortmund im ersten\"\nFrame a to e (Translation): \"Game for RB Leipzig, the team plays in white and red Borussia\nDortmund in the first\"\nFigure 5: Example transcription using Whisper and translation to English using Google Translate\n(original audio in German). Key frames are shown to represent the corresponding video segment.\n(a)\n (b)\n (c)\n (d)\n (e)\nAutomatic Russian Transcription and English Translation\nFrame a to e (Transcription):\"\u041d\u0443 \u0447\u0442\u043e, \u043f\u043e\u0445\u043e\u0436\u0435 \u0431\u0443\u0434\u0435\u0442 \u043f\u0440\u044f\u043c\u043e\u0439 \u0443\u0434\u0430\u0440. \u041c\u0443\u0440\u0435\u043b\u044c \u043f\u043e\u043f\u0430\u0434\u0430\u0435\u0442 \u0432\n\u041b\u043e\u043f\u043e\u0434\u0443\u043b\u0443, \u043a\u043e\u0442\u043e\u0440\u044b\u0439, \u043f\u043e \u0435\u0433\u043e \u043c\u043d\u0435\u043d\u0438\u044e, \u0438\u0433\u0440\u0430\u043b \u0440\u0443\u043a\u043e\u0439. \u041d\u043e \u041b\u043e\u043f\u043e\u0434\u0443\u043b\u0443 \u0441\u0440\u0430\u0437\u0443 \u043f\u043e\u0434\u0445\u0432\u0430\u0442\u044b\u0432\u0430\u0435\u0442\n\u043c\u044f\u0447. \u0412\u0441\u0435-\u0442\u0430\u043a\u0438, \u0434\u0430, \u043f\u043e\u0434\u0443\u043c\u0430\u0432, \u043f\u043e\u0434\u0443\u043c\u0430\u0432, \u041c\u0430\u0441\u0438\u043c\u0438\u043b\u0438\u0430\u043d\u0443 \u0410\u0440\u0430\u0442\u0435 \u043d\u0430\u0437\u043d\u0430\u0447\u0430\u0435\u0442 \u0448\u0442\u0440\u0430\u0444\u043d\u043e\u0439.\n\u041e\u043d \u043f\u043e\u0441\u043b\u0443\u0448\u0430\u043b \u0432\u044b\u0433\u043e\u043d \u043f\u043e\u043c\u043e\u0449\u043d\u0438\u043a\u0430. \u041f\u043e\u043a\u0430\u0437\u044b\u0432\u0430\u0435\u0442 \u041b\u043e\u043f\u043e\u0434\u0443\u043b\u0443 \u0436\u0435\u043b\u0442\u0443\u044e \u043a\u0430\u0440\u0442\u043e\u0447\u043a\u0443.\"\nFrame a to e (Translation): \"Well, it looks like it\u2019s going to be a direct hit. Murel ends up in\nLopodula, who, in his opinion, played with his hand. But Lopodulu immediately picks up the\nball. Still, yes, after thinking, after thinking, he appoints Masimiliana Arata penalty. He listened\nto the assistant\u2019s drive. Shows Lopodul a yellow card.\"\nFigure 6: Example transcription using Whisper and translation to English using Google Translate\n(original audio in Russian). Key frames are shown to represent the corresponding video segment.\nspeech, which provides a textual representation of the commentary content. Figure 10 presents the\nstructure of the ASR JSON files.\n4 Evaluation\nFor evaluating the transcription and translations in the SoccerNet-Echoes dataset, we conducted an\nanalysis that uses Word Error Rate (WER), Character Error Rate (CER), BLEU score, and word\ncount as metrics. These metrics are crucial for discerning linguistic richness and accuracy.\n4.1 Comparison with Verified Transcriptions\nTo evaluate the transcription performance, we conducted a comparative analysis using manually veri-\nfied transcriptions from the GOAL dataset [26]. This dataset comprises human-verified transcriptions\nfrom 40 game half videos across 20 games with original commentary in English from the SoccerNet\n6", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2192, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "be52189c-38c8-4808-8359-fdbb5ff22fdd": {"__data__": {"id_": "be52189c-38c8-4808-8359-fdbb5ff22fdd", "embedding": null, "metadata": {"page_label": "7", "file_name": "2405.07354v1.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2405.07354v1.pdf", "file_type": "application/pdf", "file_size": 38960451, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b93d8596-9d3a-4fd5-916e-f50a19cdb91b", "node_type": "4", "metadata": {"page_label": "7", "file_name": "2405.07354v1.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2405.07354v1.pdf", "file_type": "application/pdf", "file_size": 38960451, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "hash": "d2f2b8e0b90c8e55c6b704d852af51078bdec1d25f001241a3838c43fc5f732d", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "dataset. We assessed the transcription performance of Whisper large-v1/v2/v3 on these 40 videos\nagainst ground truth transcriptions from the GOAL dataset using WER, CER, and BLEU score as\nmetrics. The results are presented in Table 1.\nModel WER CER BLEU\nWhisper large-v1 0.443 0.261 54.50\nWhisper large-v2 0.458 0.269 52.59\nWhisper large-v3 0.551 0.341 47.97\nTable 1: Transcription performance for different Whisper models [25] against ground truth informa-\ntion from the GOAL dataset [26], averaged over the 20 games for which ground truth transcriptions\nare available.\n4.2 Model Selection\nWe implemented a \"Unique Word Count\" heuristic as a criterion to identify the most effective ASR\nmodel among the different Whisper versions. This approach facilitated the selection of the best-\nperforming model for each game half based on the diversity of vocabulary in the transcriptions, and\nproved particularly valuable as a heuristic for assessing model performance in scenarios prone to\nrepeated content, often manifesting as hallucinations (erroneously repeated phrases in the transcrip-\ntion, which are not actually present in the audio). This metric effectively captures the ability of ASR\nmodels to generate diverse linguistic outputs, which is crucial for minimizing the impact of such\nrepetitions.\nFor each game half video, we selected the model with the highest unique word count as the \"best\"\nmodel for further analysis and application. This selection criterion is anchored on the premise that a\nhigher diversity in word usage is indicative of reduced hallucinatory repetitions and, by extension, a\nmore robust transcription performance in diverse acoustic environments. Table 2 presents the average\nunique word ratio (unique word count divided by the the number of total words) for different Whisper\nmodels, averaged over the videos for which the model was selected to be the \"best\". A pie chart\ndepicting the distribution of selected Whisper models is given in Figure 7.\nModel Number of Videos Average Unique Word Ratio\nWhisper large-v1 316 0.311\nWhisper large-v2 231 0.316\nWhisper large-v3 483 0.370\nMixed Selection 1030 0.340\nTable 2: Average unique word ratio (number of unique words / number of total words) for different\nWhisper models. \"Mixed Selection\" represents the overall weighted average across a total of 1030\ngame half videos with valid commentary, using the \"best\" model for each video.\n30.7%\n22.4%\n46.9%\nWhisper large-v1 (316)\nWhisper large-v2 (231)\nWhisper large-v3 (483)\nFigure 7: Distribution of the selected Whisper models, for a total of 1030 game half videos with valid\ncommentary.\n7", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2611, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "5cef45c2-56df-434e-95b5-6ac7d0f0497c": {"__data__": {"id_": "5cef45c2-56df-434e-95b5-6ac7d0f0497c", "embedding": null, "metadata": {"page_label": "8", "file_name": "2405.07354v1.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2405.07354v1.pdf", "file_type": "application/pdf", "file_size": 38960451, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "dd493c2b-26fb-4a4d-b247-07a3e4ac26b5", "node_type": "4", "metadata": {"page_label": "8", "file_name": "2405.07354v1.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2405.07354v1.pdf", "file_type": "application/pdf", "file_size": 38960451, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "hash": "b4929bc685494f2e71e052361318ba25065da236ae439020cd5502a9515c9855", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "4.3 Vocabulary Analysis\nWe conducted an in-depth examination of the linguistic patterns in the soccer game commentaries\nto identify prevalent verb-noun pairs, which are key to understanding the action dynamics that are\ndescribed. Utilizing Natural Language Processing (NLP) techniques, we parsed the transcriptions\nto extract named entities and specific grammatical structures, focusing on the interactions between\nplayers and teams. We then applied dependency parsing models to determine the dominant actions by\nidentifying root verbs and their direct objects, providing clarity on the primary activities depicted.\nWe conducted a sunburst visualization to represent the frequency and distribution of verb-noun\ncombinations, displaying verbs as primary segments with corresponding nouns as sub-segments. This\nvisualization, exemplified for one game half in Figure 8, not only highlights predominant actions but\nalso showcases vocabulary diversity. Such analyses offer insights into sports broadcasting narrative\nstyles and can guide improvements in automated commentary systems.\n(a) Ground truth transcription\nfrom GOAL dataset\n (b) Whisper large-v1\n (c) Whisper large-v3\nFigure 8: Sunburst plots representing the frequency of verb-noun combinations in the audio commen-\ntary transcription for one game half.\n5 Discussion\n5.1 Dataset Applications\nThe augmentation of the SoccerNet dataset to include ASR data significantly enriches the multimodal\nnature of the dataset, enabling a broad range of applications which can leverage the combined\nstrengths of video, audio, and now textual data derived from spoken commentary. These applications\nare fundamentally enabled by enhanced content understanding, i.e., the possibility to train automated\nsystems which can more effectively understand, interpret, and generate soccer-related multimedia\ncontent, including an increased contextual awareness for actions, in-game events, highlights/statistics,\nand entities (e.g., teams, players, locations). Below, we discuss several potential applications of the\nSoccerNet-Echoes dataset.\nMulti-modal event detection: The integration of ASR data can enable more sophisticated and\naccurate event detection mechanisms. Combining audio cues (such as crowd noise and commentator\nexcitement) and textual triggers from the transcription (such as specific phrases indicating goals or\nfouls) with visual data can improve the precision and recall of event detection. Such integration\nis pivotal for real-time analytics, automated highlight generation, and conducting more detailed\nstatistical analysis. The transcription example depicted in Figure 5 showcases the advantages of ASR\nin this context. In scenarios where the sole analysis of video frames (e.g., based on the zoomed-out\nshots of the soccer pitch as shown in Figures 5a-5e) might fail to yield detailed information, ASR\ncan provide contextual information, and allow for the extraction of additional details (such as the\nidentification of the teams, and whether they are wearing home or away jerseys), which might not be\ndiscernible from the visual data alone.\nGame summarization: Automated systems can generate insightful and context-rich summaries\nof soccer games using the textual modality. This involves not just identifying key events, but also\nunderstanding their significance within the game\u2019s narrative, as well as the entities involved. For\n8", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3388, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "0dacf27b-723a-4298-8bf8-c72744802ff9": {"__data__": {"id_": "0dacf27b-723a-4298-8bf8-c72744802ff9", "embedding": null, "metadata": {"page_label": "9", "file_name": "2405.07354v1.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2405.07354v1.pdf", "file_type": "application/pdf", "file_size": 38960451, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "8dc1016c-6186-4e3b-9ebc-606da2cecd39", "node_type": "4", "metadata": {"page_label": "9", "file_name": "2405.07354v1.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2405.07354v1.pdf", "file_type": "application/pdf", "file_size": 38960451, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "hash": "06d2a3bd2f4f6a27e78a4016269aafd9e15e79f19c9f38af5b7e371da7f2b7a4", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "example, the frequency with which a player\u2019s name is mentioned during a crucial moment in the\ngame can indicate the level of their influence, which can be used for assigning an appropriate amount\nof the overall word budget for the player in the description of the action.\nAutomated soccer commentator: Commentary datasets such as SoccerNet-Echoes up exciting\npossibilities for the development of automated real-time soccer game commentator systems. With\nincreasingly more datasets available for training, models can be trained to create more realistic and\ncontextually relevant, but also dynamic and captivating commentary, potentially offering elevated\nlevels of immersion and engagement for the fans.\nTactical analysis: In certain cases, the ASR data can also provide a context for tactical analysis, by\nenabling an understanding of the discussions made by commentators based on the tactical adjustments\nmade by the coaches during soccer games. In this sense, spoken commentary provides a layer of\nstrategic insight that is typically not captured by video and audio alone. These insights can then also\nbe integrated with various audio cues (such as the audio intensity levels from the stadium) to pinpoint\nand map tactical highlights to important fan moments within the game.\nThese applications demonstrate the significant potential of the SoccerNet-Echoes dataset to contribute\nto sports research and broadcasting. Using the power of multimodal data, researchers and developers\ncan create more sophisticated tools that address a wide range of needs within the sports community.\n5.2 Limitations and Future Work\nOur use of deep learning models for ASR and batch translation for the curation of the SoccerNet-\nEchoes dataset have also introduced a number of limitations. We aim to address several of the\nfollowing challenges in future work.\nTranscription accuracy: The inference capability and accuracy of the ASR models are inherently\nconstrained by their design, occasionally leading to errors in transcription.\nHallucinations: Whisper models are known to be prone to hallucinations (unwarranted repetition\nof phrases and words). During the curation of the SoccerNet-Echoes dataset, we have observed\nhallucinations across all Whisper ASR models, especially under conditions where the audio inputs\nwere devoid of human speech, were excessively noisy, or contained musical elements. Such conditions\nsignificantly challenge transcription accuracy of the models, leading to the anomalous generation\nof repeated phrases. These repetitions not only degrade the quality of the transcription, but also\naffect the usability of the transcribed text in downstream applications, such as subtitle generation or\nvoice-driven gameplay interaction. By analyzing the occurrences of repeated words under various\naudio conditions, we aimed to understand the strengths and limitations of different models.\nAudio quality: As mentioned above, we have seen that the quality of the audio to be transcribed\nsignificantly impacts the reliability of the transcriptions. Implementing advanced audio pre-processing\ntechniques to filter out background noise and music could enhance the clarity of the input signal for\nASR systems. Combining Whisper with other technologies such as V oice Activity Detection (V AD)\ncould also help reduce ASR errors and hallucinations.\nHuman verification: The absence of human-verified annotations to serve as ground truth poses a\nsubstantial challenge for all ASR datasets. Generating such annotations is prohibitively expensive,\nthus limiting the ability of researchers to comprehensively verify and refine ASR datasets. However,\nthis limitation is also critical to address, in order to advance the reliability and applicability of our\nSoccerNet-Echoes dataset. We therefore plan to invest in the curation of human-verified annotations,\nfor a subset of the assets in SoccerNet-Echoes, as future work. Despite being expensive, we believe\nthat such a dataset could provide a valuable benchmark for assessing and improving ASR accuracy.\nEfforts could also involve collaborations with various academic institutions and community-sourcing\nthe annotations.\nBatch translations: Machine translation systems, such as Google Translate, are not infallible and\ntheir limitations must be acknowledged. When translations are performed on entire texts at once, they\ncan produce different outputs compared to translations of specific, smaller segments. For instance, as\ndepicted in Figure 6, the Russian term \"\u0448\u0442\u0440\u0430\u0444\u043d\u043e\u0439\" was erroneously translated as \"penalty kick\"\nwhen the entire game half was translated, contrasting with the accurate translation \"free kick\" when\nonly the segment was translated. This discrepancy underscores the contextual challenges faced by\nmachine translation.\n9", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4775, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e7c52956-4607-4f28-ac70-101228ae4b0e": {"__data__": {"id_": "e7c52956-4607-4f28-ac70-101228ae4b0e", "embedding": null, "metadata": {"page_label": "10", "file_name": "2405.07354v1.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2405.07354v1.pdf", "file_type": "application/pdf", "file_size": 38960451, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "edba1f4c-e4fa-4738-ad9a-8ce38c8b4041", "node_type": "4", "metadata": {"page_label": "10", "file_name": "2405.07354v1.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2405.07354v1.pdf", "file_type": "application/pdf", "file_size": 38960451, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "hash": "e2db6242011aa573c75d124ba0c708a3f254dfe2d6aab083ecea643be4bc2a61", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "6 Conclusion\nThe augmentation of the SoccerNet dataset using ASR technology marks a pivotal advance in the\ndomain of sports analytics, providing a richer and more integrated approach to understanding soccer\ngames. The inclusion of multimodal data not only aids in the accurate detection and description of\nin-game events but also enriches the dataset\u2019s applicability across various analytical tasks such as\nsentiment analysis and tactical assessments. Despite the limitations associated with ASR, such as\npotential inaccuracies and hallucinations under challenging audio conditions, the benefits presented\nby the SoccerNet-Echoes dataset are substantial. Future work will focus on refining ASR accuracy\nthrough the curation of a human-verified annotation subset and the implementation of advanced audio\npre-processing techniques. By continually improving the dataset\u2019s quality and the methodologies used\nto analyze it, SoccerNet-Echoes is poised to significantly influence the development of automated\nsystems for sports broadcasting and analytics, enhancing the consumption and comprehension of\nsports events globally. This work not only underscores the transformative impact of integrating ASR\ninto sports video analysis but also sets a precedent for future research in the field, promising deeper\ninsights and more effective tools for researchers, sports analytics professionals, and enthusiasts.\nAcknowledgement\nThis work was partly funded by the Research Council of Norway, project number 346671 (AI-\nStoryteller), and has benefited from the Experimental Infrastructure for Exploration of Exascale\nComputing (eX3), which is financially supported by the Research Council of Norway under contract\n270053.\nReferences\n[1] M. Barnard, J.-M. Odobez, and S. Bengio. Multi-modal audio-visual event recognition for\nfootball analysis. In IEEE XIII Workshop on Neural Networks for Signal Processing (IEEE Cat.\nNo.03TH8718), pages 17\u201319. IEEE, 2003. ISBN 978-0-7803-8177. doi: 10.1109/NNSP.2003.\n1318046.\n[2] Bruno Cabado, Anthony Cioppa, Silvio Giancola, Andr\u00e9s Villa, Bertha Guijarro-Berdinas,\nEmilio J Padr\u00f2n, Bernard Ghanem, and Marc Van Droogenbroeck. Beyond the premier:\nAssessing action spotting transfer capability across diverse domains. In IEEE/CVF Conference\non Computer Vision and Pattern Recognition Workshops (CVPRW), CVsports, 2024.\n[3] Yuh-Lin Chang, Wenjun Zeng, I. Kamel, and R. Alonso. Integrated image and speech analysis\nfor content-based video indexing. In Proceedings of the Third IEEE International Conference\non Multimedia Computing and Systems, pages 17\u201323. IEEE, 1996. ISBN 978-0-8186-7438.\ndoi: 10.1109/MMCS.1996.534992.\n[4] Anthony Cioppa, Adrien Deli\u00e8ge, Silvio Giancola, Bernard Ghanem, and Marc Van Droogen-\nbroeck. Scaling up SoccerNet with multi-view spatial localization and re-identification. Sci.\nData, 9(1):1\u20139, Jun. 2022. doi: 10.1038/s41597-022-01469-1. URL https://doi.org/10.\n1038/s41597-022-01469-1 .\n[5] Anthony Cioppa, Silvio Giancola, Adrien Deliege, Le Kang, Xin Zhou, Zhiyu Cheng, Bernard\nGhanem, and Marc Van Droogenbroeck. SoccerNet-tracking: Multiple object tracking dataset\nand benchmark in soccer videos. In IEEE Int. Conf. Comput. Vis. Pattern Recognit. Work.\n(CVPRW), CVsports, pages 3490\u20133501, New Orleans, LA, USA, Jun. 2022. Inst. Electr. Electron.\nEng. (IEEE). doi: 10.1109/cvprw56347.2022.00393. URL https://doi.org/10.1109/\nCVPRW56347.2022.00393.\n[6] Anthony Cioppa, Silvio Giancola, Vladimir Somers, Floriane Magera, Xin Zhou, Hassan\nMkhallati, et al. SoccerNet 2023 Challenges Results. arXiv, Sept. 2023. doi: 10.48550/arXiv.\n2309.06006.\n10", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3596, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "990b7974-e3b2-4a42-b580-37a730741fb6": {"__data__": {"id_": "990b7974-e3b2-4a42-b580-37a730741fb6", "embedding": null, "metadata": {"page_label": "11", "file_name": "2405.07354v1.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2405.07354v1.pdf", "file_type": "application/pdf", "file_size": 38960451, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "a03af834-8fe0-401b-8811-ec6904c76f48", "node_type": "4", "metadata": {"page_label": "11", "file_name": "2405.07354v1.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2405.07354v1.pdf", "file_type": "application/pdf", "file_size": 38960451, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "hash": "8c28812d9e484543fa5f7238e0895d9bbff2949bc5fe29e56478dd34d8f53beb", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e7b22d09-08d1-46fe-96cd-14700b5b8bf9", "node_type": "1", "metadata": {}, "hash": "a8b336f8a643b67e6cfa91983270cab155a8dd866fb7f66d62f38a6cdd7aff8d", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "[7] Adrien Deli\u00e8ge, Anthony Cioppa, Silvio Giancola, Meisam J. Seikavandi, Jacob V . Dueholm,\nKamal Nasrollahi, et al. SoccerNet-v2: A Dataset and Benchmarks for Holistic Understanding\nof Broadcast Soccer Videos. In 2021 IEEE/CVF Conference on Computer Vision and Pattern\nRecognition Workshops (CVPRW), pages 19\u201325. IEEE, 2021. doi: 10.1109/CVPRW53098.\n2021.00508.\n[8] Xin Gao, Xusheng Liu, Taotao Yang, Guilin Deng, Hao Peng, Qiaosong Zhang, et al. Automatic\nKey Moment Extraction and Highlights Generation Based on Comprehensive Soccer Video\nUnderstanding. In 2020 IEEE International Conference on Multimedia & Expo Workshops\n(ICMEW), pages 06\u201310. IEEE, 2020. doi: 10.1109/ICMEW46912.2020.9106051.\n[9] Sushant Gautam. Bridging Multimedia Modalities: Enhanced Multimodal AI Understanding\nand Intelligent Agents. In ICMI \u201923: Proceedings of the 25th International Conference on\nMultimodal Interaction, pages 695\u2013699. Association for Computing Machinery, New York, NY ,\nUSA, Oct. 2023. ISBN 979-840070055-2. doi: 10.1145/3577190.3614225.\n[10] Sushant Gautam, Cise Midoglu, Saeed Shafiee Sabet, Dinesh Baniya Kshatri, and P\u00e5l Halvorsen.\nSoccer Game Summarization using Audio Commentary, Metadata, and Captions. In NarSUM\n\u201922: Proceedings of the 1st Workshop on User-centric Narrative Summarization of Long Videos,\npages 13\u201322. Association for Computing Machinery, New York, NY , USA, Oct. 2022. ISBN\n978-1-45039493-2. doi: 10.1145/3552463.3557019.\n[11] Sushant Gautam, Cise Midoglu, Saeed Shafiee Sabet, Dinesh Baniya Kshatri, and P\u00e5l\nHalvorsen. Assisting soccer game summarization via audio intensity analysis of game high-\nlights. In Proc. 12th IOE Graduate Conference, pages 25\u201332. Inst. of Eng. Tribhuvan Univer-\nsity, Nepal, Oct. 2022. URL http://conference.ioe.edu.np/publications/ioegc12/\nIOEGC-12-004-12009.pdf .\n[12] Silvio Giancola, Mohieddine Amine, Tarek Dghaily, and Bernard Ghanem. SoccerNet: A\nScalable Dataset for Action Spotting in Soccer Videos. In 2018 IEEE/CVF Conference on\nComputer Vision and Pattern Recognition Workshops (CVPRW), pages 18\u201322. IEEE, 2018. doi:\n10.1109/CVPRW.2018.00223.\n[13] Google. Google Translate, Apr. 2024. [Online; https://translate.google.com].\n[14] Jan Held, Anthony Cioppa, Silvio Giancola, Abdullah Hamdi, Bernard Ghanem, and Marc\nVan Droogenbroeck. V ARS: Video assistant referee system for automated soccer decision mak-\ning from multiple views. In IEEE/CVF Conf. Comput. Vis. Pattern Recognit. Work. (CVPRW),\npages 5086\u20135097, Vancouver, Can., Jun. 2023. Inst. Electr. Electron. Eng. (IEEE). doi: 10.1109/\ncvprw59228.2023.00537. URL https://doi.org/10.1109/CVPRW59228.2023.00537.\n[15] Jan Held, Hani Itani, Anthony Cioppa, Silvio Giancola, Bernard Ghanem, and Marc\nVan Droogenbroeck. X-vars: Introducing explainability in football refereeing with multi-modal\nlarge language models. In IEEE Int. Conf. Comput. Vis. Pattern Recognit. Work. (CVPRW),\nCVsports, Seattle, W A, USA, Jun. 2024.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2936, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e7b22d09-08d1-46fe-96cd-14700b5b8bf9": {"__data__": {"id_": "e7b22d09-08d1-46fe-96cd-14700b5b8bf9", "embedding": null, "metadata": {"page_label": "11", "file_name": "2405.07354v1.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2405.07354v1.pdf", "file_type": "application/pdf", "file_size": 38960451, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "a03af834-8fe0-401b-8811-ec6904c76f48", "node_type": "4", "metadata": {"page_label": "11", "file_name": "2405.07354v1.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2405.07354v1.pdf", "file_type": "application/pdf", "file_size": 38960451, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "hash": "8c28812d9e484543fa5f7238e0895d9bbff2949bc5fe29e56478dd34d8f53beb", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "990b7974-e3b2-4a42-b580-37a730741fb6", "node_type": "1", "metadata": {"page_label": "11", "file_name": "2405.07354v1.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2405.07354v1.pdf", "file_type": "application/pdf", "file_size": 38960451, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "hash": "8ec346b369717c2a8970d4b72f94999f1e79af3251edb3a9c27c7e574bcf1cc7", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Comput. Vis. Pattern Recognit. Work. (CVPRW),\npages 5086\u20135097, Vancouver, Can., Jun. 2023. Inst. Electr. Electron. Eng. (IEEE). doi: 10.1109/\ncvprw59228.2023.00537. URL https://doi.org/10.1109/CVPRW59228.2023.00537.\n[15] Jan Held, Hani Itani, Anthony Cioppa, Silvio Giancola, Bernard Ghanem, and Marc\nVan Droogenbroeck. X-vars: Introducing explainability in football refereeing with multi-modal\nlarge language models. In IEEE Int. Conf. Comput. Vis. Pattern Recognit. Work. (CVPRW),\nCVsports, Seattle, W A, USA, Jun. 2024.\n[16] Jack Hessel, Bo Pang, Zhenhai Zhu, and Radu Soricut. A Case Study on Combining ASR and\nVisual Features for Generating Instructional Video Captions. ACL Anthology, pages 419\u2013429,\nNov. 2019. doi: 10.18653/v1/K19-1039.\n[17] Riku Ikeda, Kazuma Sakamoto, and Yoshihiro Ueda. Breaking News System of At-Bat Results\nFrom Sports Commentary via Speech Recognition. IEEE Access, 12:27199\u201327209, Feb. 2024.\nISSN 2169-3536. doi: 10.1109/ACCESS.2024.3365948.\n[18] Ranjay Krishna, Kenji Hata, Frederic Ren, Li Fei-Fei, and Juan Carlos Niebles. Dense-\nCaptioning Events in Videos. In 2017 IEEE International Conference on Computer Vision\n(ICCV), pages 22\u201329. IEEE, 2017. doi: 10.1109/ICCV .2017.83.\n[19] Vladimir Lashin and Esa Rahtu. Multi-modal Dense Video Captioning. IEEE Computer Society,\nJun. 2020. ISBN 978-1-7281-9360-1. doi: 10.1109/CVPRW50498.2020.00487.\n[20] Jinyu Li. Recent Advances in End-to-End Automatic Speech Recognition. SIP, 11(1), Apr.\n2022. doi: 10.1561/116.00000050.\n11", "mimetype": "text/plain", "start_char_idx": 2414, "end_char_idx": 3919, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "21238e9f-fda8-4388-8e2d-f5bdae7eab76": {"__data__": {"id_": "21238e9f-fda8-4388-8e2d-f5bdae7eab76", "embedding": null, "metadata": {"page_label": "12", "file_name": "2405.07354v1.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2405.07354v1.pdf", "file_type": "application/pdf", "file_size": 38960451, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "cf1c79c5-9a9f-47bb-976c-e6ff6f523638", "node_type": "4", "metadata": {"page_label": "12", "file_name": "2405.07354v1.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2405.07354v1.pdf", "file_type": "application/pdf", "file_size": 38960451, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "hash": "dae6090bae14fc97b6ff9155d738332a1f77cca2ecdda900a51ee05f61c34d3d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d7769b81-6b5d-4ca3-9ed9-6ae5672df044", "node_type": "1", "metadata": {}, "hash": "efcddbb8851410dee88a71905ec904936fa3cd2fb5f7b2e2b738b1effe9791cc", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "[21] Yao Lu and Shuyang An. Research on sports video detection technology motion 3D reconstruc-\ntion based on hidden Markov model. Cluster Comput., 23(3):1899\u20131909, Sept. 2020. ISSN\n1573-7543. doi: 10.1007/s10586-020-03097-z.\n[22] Mishaim Malik, Muhammad Kamran Malik, Khawar Mehmood, and Imran Makhdoom. Auto-\nmatic speech recognition: a survey. Multimed. Tools Appl., 80(6):9411\u20139457, Mar. 2021. ISSN\n1573-7721. doi: 10.1007/s11042-020-10073-7.\n[23] Hassan Mkhallati, Anthony Cioppa, Silvio Giancola, Bernard Ghanem, and Marc Van Droogen-\nbroeck. SoccerNet-Caption: Dense Video Captioning for Soccer Broadcasts Commentaries. In\n2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW),\npages 17\u201324. IEEE, 2023. doi: 10.1109/CVPRW59228.2023.00536.\n[24] Hassan Mkhallati, Anthony Cioppa, Silvio Giancola, Bernard Ghanem, and Marc Van Droogen-\nbroeck. SoccerNet-caption: Dense video captioning for soccer broadcasts commentaries. In\nIEEE/CVF Conf. Comput. Vis. Pattern Recognit. Work. (CVPRW), pages 5074\u20135085, Vancouver,\nCan., Jun. 2023. Inst. Electr. Electron. Eng. (IEEE). doi: 10.1109/cvprw59228.2023.00536.\nURL https://doi.org/10.1109/CVPRW59228.2023.00536.\n[25] OpenAI. Whisper. GitHub, Apr. 2024. [Online; https://github.com/openai/whisper].\n[26] Ji Qi, Jifan Yu, Teng Tu, Kunyu Gao, Yifan Xu, Xinyu Guan, et al. GOAL: A Challenging\nKnowledge-grounded Video Captioning Benchmark for Real-time Soccer Commentary Genera-\ntion. In CIKM \u201923: Proceedings of the 32nd ACM International Conference on Information and\nKnowledge Management, pages 5391\u20135395. Association for Computing Machinery, New York,\nNY , USA, Oct. 2023. ISBN 979-840070124-5. doi: 10.1145/3583780.3615120.\n[27] Husnain Sattar, Muhammad Shamil Umar, Eeman Ijaz, and Muhammad Umair Arshad. Multi-\nModal Architecture for Cricket Highlights Generation: Using Computer Vision and Large\nLanguage Model. In 2023 17th International Conference on Open Source Systems and Tech-\nnologies (ICOSST), pages 20\u201321. IEEE, 2023. doi: 10.1109/ICOSST60641.2023.10414235.\n[28] Paul Hongsuck Seo, Arsha Nagrani, Anurag Arnab, and Cordelia Schmid. End-to-end Genera-\ntive Pretraining for Multimodal Video Captioning. IEEE Computer Society, Jun. 2022. ISBN\n978-1-6654-6946-3. doi: 10.1109/CVPR52688.2022.01743.\n[29] Huang-Chia Shih. A Survey of Content-Aware Video Analysis for Sports. IEEE Trans. Circuits\nSyst. Video Technol., 28(5):1212\u20131231, Jan. 2017. doi: 10.1109/TCSVT.2017.2655624.\n[30] Mattia Soldan, Alejandro Pardo, Juan Le\u00f3n Alc\u00e1zar, Fabian Caba, Chen Zhao, Silvio Giancola,\nand Bernard Ghanem. Mad: A scalable dataset for language grounding in videos from movie\naudio descriptions. In Proceedings of the IEEE/CVF Conference on Computer Vision and\nPattern Recognition (CVPR), pages 5026\u20135035, June 2022.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2790, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "d7769b81-6b5d-4ca3-9ed9-6ae5672df044": {"__data__": {"id_": "d7769b81-6b5d-4ca3-9ed9-6ae5672df044", "embedding": null, "metadata": {"page_label": "12", "file_name": "2405.07354v1.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2405.07354v1.pdf", "file_type": "application/pdf", "file_size": 38960451, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "cf1c79c5-9a9f-47bb-976c-e6ff6f523638", "node_type": "4", "metadata": {"page_label": "12", "file_name": "2405.07354v1.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2405.07354v1.pdf", "file_type": "application/pdf", "file_size": 38960451, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "hash": "dae6090bae14fc97b6ff9155d738332a1f77cca2ecdda900a51ee05f61c34d3d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "21238e9f-fda8-4388-8e2d-f5bdae7eab76", "node_type": "1", "metadata": {"page_label": "12", "file_name": "2405.07354v1.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2405.07354v1.pdf", "file_type": "application/pdf", "file_size": 38960451, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "hash": "fb6a4ee57f5513147dbd08f18561be1cdc1bf72b56d107965de67674fab89931", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "2022. ISBN\n978-1-6654-6946-3. doi: 10.1109/CVPR52688.2022.01743.\n[29] Huang-Chia Shih. A Survey of Content-Aware Video Analysis for Sports. IEEE Trans. Circuits\nSyst. Video Technol., 28(5):1212\u20131231, Jan. 2017. doi: 10.1109/TCSVT.2017.2655624.\n[30] Mattia Soldan, Alejandro Pardo, Juan Le\u00f3n Alc\u00e1zar, Fabian Caba, Chen Zhao, Silvio Giancola,\nand Bernard Ghanem. Mad: A scalable dataset for language grounding in videos from movie\naudio descriptions. In Proceedings of the IEEE/CVF Conference on Computer Vision and\nPattern Recognition (CVPR), pages 5026\u20135035, June 2022.\n[31] Vladimir Somers, Victor Joos, Silvio Giancola, Anthony Cioppa, Seyed Abolfazl Ghasemzadeh,\nFloriane Magera, Baptiste Standaert, Amir Mohammad Mansourian, Xin Zhou, Shohreh Kasaei,\nBernard Ghanem, Alexandre Alahi, Marc Van Droogenbroeck, and Christophe De Vleeschouwer.\nSoccerNet game state reconstruction: End-to-end athlete tracking and identification on a\nminimap. In IEEE Int. Conf. Comput. Vis. Pattern Recognit. Work. (CVPRW), CVsports, Seattle,\nW A, USA, Jun. 2024.\n[32] Khurram Soomro, Amir Roshan Zamir, and Mubarak Shah. UCF101: A Dataset of 101 Human\nActions Classes From Videos in The Wild. arXiv, Dec. 2012. doi: 10.48550/arXiv.1212.0402.\n[33] Richard Szeliski. Computer Vision. Springer International Publishing, Cham, Switzerland,\n2022. ISBN 978-3-030-34372-9. URL https://link.springer.com/book/10.1007/\n978-3-030-34372-9 .\n[34] Bastien Vanderplaetse and St\u00e9phane Dupont. Improved Soccer Action Spotting using both Audio\nand Video Streams. In2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition\nWorkshops (CVPRW), pages 14\u201319. IEEE, 2020. doi: 10.1109/CVPRW50498.2020.00456.\n12", "mimetype": "text/plain", "start_char_idx": 2221, "end_char_idx": 3903, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "fdcf0c5b-cf41-451f-87f2-502da726e58e": {"__data__": {"id_": "fdcf0c5b-cf41-451f-87f2-502da726e58e", "embedding": null, "metadata": {"page_label": "13", "file_name": "2405.07354v1.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2405.07354v1.pdf", "file_type": "application/pdf", "file_size": 38960451, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "6b404874-c543-4846-8fd8-ced63d78166a", "node_type": "4", "metadata": {"page_label": "13", "file_name": "2405.07354v1.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2405.07354v1.pdf", "file_type": "application/pdf", "file_size": 38960451, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "hash": "ef2162bb95aa5835eca8f02f3641751fcdf2c274d057d9912497b0827750ab26", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "[35] Yue Yin, Daijiro Mori, and Seiji Fujimoto. Reazonspeech: A free and massive corpus for\njapanese asr. In Proceedings of the 29th Annual Conference of the Language Processing Society\n(NLP 2023), March 2023.\n[36] Zixing Zhang, J\u00fcrgen Geiger, Jouni Pohjalainen, Amr El-Desoky Mousa, Wenyu Jin, and\nBj\u00f6rn Schuller. Deep Learning for Environmentally Robust Speech Recognition: An Overview\nof Recent Developments. ACM Trans. Intell. Syst. Technol., 9(5):1\u201328, Apr. 2018. ISSN\n2157-6904. doi: 10.1145/3178115.\n13", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 509, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "60320fb0-420a-4b86-a7c8-6ae1b7409b2f": {"__data__": {"id_": "60320fb0-420a-4b86-a7c8-6ae1b7409b2f", "embedding": null, "metadata": {"page_label": "14", "file_name": "2405.07354v1.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2405.07354v1.pdf", "file_type": "application/pdf", "file_size": 38960451, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "1c0ade49-d780-4ac7-b99b-48480f85a7ef", "node_type": "4", "metadata": {"page_label": "14", "file_name": "2405.07354v1.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2405.07354v1.pdf", "file_type": "application/pdf", "file_size": 38960451, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}, "hash": "2146b0256a848ccee4e943e7d641e8ca6ce077abc6d0d7371a4c0d8bb6743e57", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "APPENDIX\nFigure 9 presents an overview of the SoccerNet-Echoes dataset directory under https://github.\ncom/SoccerNet/sn-echoes.\n\uf1c0 Dataset\n whisper_v1\n\u1f3cengland_epl\n\u1f4c2014-2015\n 2016-03-02-23-00 Liverpool 3-0 Manchester City\n\u2601 1_asr.json\n\u2601 2_asr.json\n...\n\u1f4c2015-2016\n...\n\u1f3ceurope_uefa-champions-league\n...\n\u1f3cfrance_ligue-1\n...\n\u1f3cgermany_bundesliga\n...\n\u1f3citaly_serie-a\n...\n\u1f3cspain_laliga\n...\n whisper_v1_en\n...\n whisper_v2\n...\n whisper_v2_en\n...\n whisper_v3\n...\n whisper_v3_en\n...\nFigure 9: SoccerNet-Echoes dataset directory structure.\nFigure 10 presents the structure of the ASR JSON files in the dataset.\n{\n\" segments \": {\n( int ) < segment index >:[\n( float ) <start time in seconds >,\n( float ) <end time in seconds >,\n( string ) < commentary text >\n],\n....\n}\n}\nFigure 10: Structure of the ASR JSON files in the SoccerNet-Echoes dataset.\n14", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 835, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}}, "docstore/metadata": {"cbb491e7-f536-4bb4-a240-c027ed4f8ae5": {"doc_hash": "91af2c16cde4e252775770f45b1aaa30d47071f7e159e19d48631831d0a8b118", "ref_doc_id": "00f122b5-dc86-43d0-8623-8fe1a1cf64c7"}, "e4677d8d-df79-4644-8ea6-a6d01e42e2cf": {"doc_hash": "2b76aefca78a727a8bb6ece3c8ab1e7792e46bdc4fccef142de9f8da7bfe2b2b", "ref_doc_id": "00f122b5-dc86-43d0-8623-8fe1a1cf64c7"}, "279397c8-a63e-4fba-ac64-9123abccafb8": {"doc_hash": "b8f7f46237658547b46d48b914120f342bc748bfe60eec3ed135445cf457f680", "ref_doc_id": "17a68a59-07dd-4e73-80dc-65ccafd2b44d"}, "1f55075e-2e8a-4038-bac7-4e5577274b93": {"doc_hash": "54a13bb8f0f8c83538073128af48beb3423ced9d231ec7902a022a777f74d4d2", "ref_doc_id": "9f1974f9-2e55-433b-98b0-5135dfe73591"}, "cb87c01d-4e29-4444-a011-1ecf255da0c1": {"doc_hash": "af8d2ae3242b5c9f4fadc02bd31a7b3bbc60fa14c4b75b52c5e9f379ce039cd5", "ref_doc_id": "cb5ddc8f-dbda-4557-a840-1e320547a0f2"}, "b041f133-4b99-4c99-94ce-0e06bb59d87e": {"doc_hash": "dc9f96d7eb11acb475411a6b4121e2863c61361e0598957cd06fbd1c1bc6d9f9", "ref_doc_id": "cb5ddc8f-dbda-4557-a840-1e320547a0f2"}, "110f2a8a-2548-4cd3-a50e-80062a6b75e8": {"doc_hash": "46e34b10bf2a1b9c3add9e08879822c529b7afd727f12cc244e66cea06e6b51a", "ref_doc_id": "9790f12d-8fbb-451b-8f20-e32e7caaf228"}, "561673fa-40e0-4c83-a8fe-f9adee1f64b2": {"doc_hash": "8ae7245c7d0706e2fe76796cb7c59dba2d3d519080fb53ef749862599f23590a", "ref_doc_id": "9790f12d-8fbb-451b-8f20-e32e7caaf228"}, "35caf51b-bcbf-4bbd-889e-1992400ffb04": {"doc_hash": "6834f3fb69652f322544e0189af64f52d2339ffbe42d2da46623fa8e7964fea3", "ref_doc_id": "d7be831c-9cf8-4ca3-a7b4-1da140047a95"}, "a76ec774-8dcf-4aee-b0e3-ee93bc0bfbc1": {"doc_hash": "7bf5c07d67c5c8dcfce3547f76349db17e2a7291fe667b9f6f67c6f33c6151ab", "ref_doc_id": "d7be831c-9cf8-4ca3-a7b4-1da140047a95"}, "1371ab67-915e-4824-ba3f-d8a7c1d1f150": {"doc_hash": "f41bdfac0568031ec666bd997586c21fa1ce7437f3930e884d2f3a46963bf83c", "ref_doc_id": "916c726b-bbe1-40ca-bcbd-9a997a1eaa24"}, "8f61dc97-461e-4bae-9b8f-386c6175fba7": {"doc_hash": "f23bb93a1044f5d3f65fe0c652a77baf93971922e1ee9f2fd7987c6ad2be8fd3", "ref_doc_id": "916c726b-bbe1-40ca-bcbd-9a997a1eaa24"}, "243f501c-9683-4423-a407-54040b76cf92": {"doc_hash": "4c833b554c15f74608ac9c0847b52fd0cfa60f06d7d589da920437a1f56a75c9", "ref_doc_id": "916c726b-bbe1-40ca-bcbd-9a997a1eaa24"}, "91b29eea-77af-4e13-acfe-8d3acbebb661": {"doc_hash": "08ebb4a79e273c8719e649d19b2374ea3ba2766a17c55435489474da5ddf43f0", "ref_doc_id": "e4dc0552-1ed3-4566-a1ab-df63dfd74b04"}, "fd216069-f79f-4890-9595-d44086a8b2d5": {"doc_hash": "bb37334228164df2ab471bbe441e39cbe5083b27926b0e27565003ee00f38dfa", "ref_doc_id": "5e69ed8e-a68c-4097-ac57-173fd1043951"}, "3b8e3c46-138f-4bca-851e-b8d03f34f6e0": {"doc_hash": "c4246f0c7c0750eaf8666bbfe7ead89a798b64a8ee6ccdf4187090ca0e39f21d", "ref_doc_id": "5e69ed8e-a68c-4097-ac57-173fd1043951"}, "1387d259-896f-46eb-966f-9d214a84f332": {"doc_hash": "ea19e34fa83ac13688d1643edce4e3240280b490d915a0897a4ae758e80f41b1", "ref_doc_id": "2a32a8f1-3309-4bf4-9559-b165fc1af324"}, "e0a0bc8b-9fdd-4763-9c72-f43301a7aaf7": {"doc_hash": "a96a8afc1b130c7ef200da88ecc74e668a7876cdbf4d631eef678c313e852022", "ref_doc_id": "2a32a8f1-3309-4bf4-9559-b165fc1af324"}, "b75389bd-45f0-4718-8d9a-9d499650b2de": {"doc_hash": "f4ea70ee4be97d51d1f394f84e6ca9286d025d1e97a3a3bcc132ac966add699f", "ref_doc_id": "31098157-5ff6-4a52-9c35-320781ea3bd4"}, "d9d4aa39-9b9e-48c5-9141-692b358b22c0": {"doc_hash": "1455b7207cb6cac66d78b83117a100a04f87d298ef2cc67f6874f78c651eb5f7", "ref_doc_id": "31098157-5ff6-4a52-9c35-320781ea3bd4"}, "5059f07b-53fc-4c41-b737-4e7bc32ea580": {"doc_hash": "83fcf20e8a98ee3f13413b65492c3e09c8a2403018393e9c425519927831b859", "ref_doc_id": "40542742-aec1-423e-8af1-02002e279650"}, "701b18cc-e46a-4173-9dbd-ae51764b94d9": {"doc_hash": "08d3c4eda0c12b123479a323b2ead94a8f99a090c39fde6f3f0380221f698799", "ref_doc_id": "40542742-aec1-423e-8af1-02002e279650"}, "2ac26ec6-8e2d-4c38-b372-87a3fbaddecb": {"doc_hash": "dd5fb76103e779bc697bdc5f2b778a1f431016dc5ad65c2102ca8930c2fc2033", "ref_doc_id": "43dbd250-fa5f-4d20-89ff-57fb0fddffb5"}, "a00703fd-9a48-486a-90ec-27c62200f4a6": {"doc_hash": "df0a7ab936d584c4536e5432bbe2b5567d14c52bd2ed436bd34db49ad84c8b01", "ref_doc_id": "ac1c7c2f-6976-4682-b5ed-b44f89aaa87e"}, "4128dbbd-104d-4975-a7d6-4a645bbd0614": {"doc_hash": "7e82a9bb8ac9bc4fbfbaf64318d80d767ef42a6e591145acc3efc59d01d5eed5", "ref_doc_id": "ac1c7c2f-6976-4682-b5ed-b44f89aaa87e"}, "4c267a67-44fb-4d51-a988-2471b5ec8d26": {"doc_hash": "9cc009899b8f871ff820da02b9896cf1dc678b7621e152c921f4f8389fed1e96", "ref_doc_id": "4bd10bab-517e-4412-aa4b-1833db2779d7"}, "a9bb14cd-c0cf-4a9d-8ba0-150893151cef": {"doc_hash": "44cb5b781f9872d84a3388b3b30676033825b6096e21071204340298d2a134b5", "ref_doc_id": "eeb7a7ba-2dbe-4411-b51b-709b06b24fb3"}, "75ca7693-3a68-4df5-b37d-bf56c8075bce": {"doc_hash": "5d1ad8797dec95ebe592fff0c4b9e4dd1471fd9b8975480b9930f2f24f53793c", "ref_doc_id": "faa5cfee-2267-4927-9d57-0d993ce6ac9e"}, "c83fe11c-cf03-4966-911c-ec6d6050ba2b": {"doc_hash": "65bacdbb9b0ad5375d42f3594fc0557687c105c73c3bcac56e1da4bdc379353a", "ref_doc_id": "faa5cfee-2267-4927-9d57-0d993ce6ac9e"}, "e2f6369c-7916-492c-8d0f-719f67737d65": {"doc_hash": "8f95254c5822cfb9271f129215b5d09a319a8a6bbcb190b1e5a1e50dc4731b2b", "ref_doc_id": "e1206ad4-2875-415d-baa2-213c96ae3fe5"}, "ba41b74f-41d8-4e0b-9478-e2ec23c11189": {"doc_hash": "8c50f6028bf375f23c21d39c0cdf81ca8188cabb82dc4391222c3f71af86611d", "ref_doc_id": "e1206ad4-2875-415d-baa2-213c96ae3fe5"}, "00bab8de-0746-4592-b9c1-7b6f10eb89ac": {"doc_hash": "a6d66d8eb9503bc68361dc35942bb063d47b53712d52076baa1e233f33e5d908", "ref_doc_id": "0c40234f-5286-4c2c-a086-028a1c41410a"}, "075e0013-e8a1-4152-b202-9a6358d40994": {"doc_hash": "da04b129c80725aa3411545820c68a54ab472e1e792eb7efa3a8f030e976fa74", "ref_doc_id": "09df8e14-4af3-4ef0-ad85-eddbe3b7a241"}, "1e543b19-ce48-4dc2-856e-b98b633dd095": {"doc_hash": "bf0ef9961f4b6bc9b525f8b2f62a535ab7f7ee829bf39e802b0e02a127a8a4c5", "ref_doc_id": "2b14664e-9550-428b-99f3-1e33ff83ad8d"}, "c6ad923d-7c21-4a7d-9087-042f11e03352": {"doc_hash": "97a6b74119422f1395aca560cc1c0c388a4b1e676e747b4787ae23e98c58b423", "ref_doc_id": "c314c64c-400b-4167-9013-34f363ed9e1b"}, "f1c3926c-4533-45ca-bd3d-012f6f72eb96": {"doc_hash": "b06bd548aadf941c0e815abec2a7b9a5b8d5faef9f8331d5994950f77b237b03", "ref_doc_id": "40b6fc40-dfdf-4ffd-90ab-f004e35f3c3e"}, "fc2a91b9-e628-44a4-9982-c7a65749f6b9": {"doc_hash": "34d511faaf88e0d47818168ef7c1f7d5092f8d5ac986927bdb37dd7ead490323", "ref_doc_id": "f2dfa0c2-590f-4686-ae13-dfbf384308b8"}, "1ba63044-7c24-42ba-ac48-c559265dba83": {"doc_hash": "dee355d7f0dc557a69e75bf39ad3450899ee86b2a813bf34a1b6c74f5fefee00", "ref_doc_id": "1d2bc51b-a218-49fc-89b5-58121dd07020"}, "f1912059-1bf8-4476-a6b6-d695974ead07": {"doc_hash": "9d47f73318137488de9a85a672f44cd4ca106c493a097edc83205f9d4ef62a9a", "ref_doc_id": "3adc0f79-a995-47df-9ae9-275863354e4c"}, "5c823c8d-56cf-4fbd-909a-aeafc1ef001b": {"doc_hash": "e0f440ca03322aa3f243bc0e49ad364fc644b35b0ff4bf59372b5fd5d4841542", "ref_doc_id": "b25b349c-450e-4ff7-9976-15274259cc14"}, "67ad840e-5392-463f-8dd8-ad474d9f57b0": {"doc_hash": "8ca989e26f0661a7bc1eb8cde396e7dcb586991873751970d01b03c7ca991a8d", "ref_doc_id": "778cfc29-bfc7-47c1-9a67-7497f4f466ff"}, "be52189c-38c8-4808-8359-fdbb5ff22fdd": {"doc_hash": "53a2be9f353e1462ea354117ce355c08470815057b9af22ec319bd41b02bb335", "ref_doc_id": "b93d8596-9d3a-4fd5-916e-f50a19cdb91b"}, "5cef45c2-56df-434e-95b5-6ac7d0f0497c": {"doc_hash": "7de6444356c132345991f8a3e14e6c166e73d439af9c0cec7d6ad58b1f87f9b4", "ref_doc_id": "dd493c2b-26fb-4a4d-b247-07a3e4ac26b5"}, "0dacf27b-723a-4298-8bf8-c72744802ff9": {"doc_hash": "5e0a4c9b8631ffbbe1c71fe14c173f279081a7b859ab8008b013a80e6285a724", "ref_doc_id": "8dc1016c-6186-4e3b-9ebc-606da2cecd39"}, "e7c52956-4607-4f28-ac70-101228ae4b0e": {"doc_hash": "4b02b61fe715d7336d93f7fefd17e44bf1045688ffedc0e57e0008408f7da7cd", "ref_doc_id": "edba1f4c-e4fa-4738-ad9a-8ce38c8b4041"}, "990b7974-e3b2-4a42-b580-37a730741fb6": {"doc_hash": "8ec346b369717c2a8970d4b72f94999f1e79af3251edb3a9c27c7e574bcf1cc7", "ref_doc_id": "a03af834-8fe0-401b-8811-ec6904c76f48"}, "e7b22d09-08d1-46fe-96cd-14700b5b8bf9": {"doc_hash": "7393575ff3d9def247540622700739412bb2fab66f914f54ea26a99d2cc715e5", "ref_doc_id": "a03af834-8fe0-401b-8811-ec6904c76f48"}, "21238e9f-fda8-4388-8e2d-f5bdae7eab76": {"doc_hash": "fb6a4ee57f5513147dbd08f18561be1cdc1bf72b56d107965de67674fab89931", "ref_doc_id": "cf1c79c5-9a9f-47bb-976c-e6ff6f523638"}, "d7769b81-6b5d-4ca3-9ed9-6ae5672df044": {"doc_hash": "ee67962c2e1ef3638579bdd817f16ab8f147332a9dc03a32ee21458347c720e6", "ref_doc_id": "cf1c79c5-9a9f-47bb-976c-e6ff6f523638"}, "fdcf0c5b-cf41-451f-87f2-502da726e58e": {"doc_hash": "99cdd248b9533b73eaf2e7e65d2fa4da8d80f8f3f8f6e60ad16f092099e229f8", "ref_doc_id": "6b404874-c543-4846-8fd8-ced63d78166a"}, "60320fb0-420a-4b86-a7c8-6ae1b7409b2f": {"doc_hash": "623fa998ee61596133131d77af4f35f7243581cf2425d8eb3ff69759bead61d7", "ref_doc_id": "1c0ade49-d780-4ac7-b99b-48480f85a7ef"}}, "docstore/ref_doc_info": {"00f122b5-dc86-43d0-8623-8fe1a1cf64c7": {"node_ids": ["cbb491e7-f536-4bb4-a240-c027ed4f8ae5", "e4677d8d-df79-4644-8ea6-a6d01e42e2cf"], "metadata": {"page_label": "1", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}}, "17a68a59-07dd-4e73-80dc-65ccafd2b44d": {"node_ids": ["279397c8-a63e-4fba-ac64-9123abccafb8"], "metadata": {"page_label": "2", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}}, "9f1974f9-2e55-433b-98b0-5135dfe73591": {"node_ids": ["1f55075e-2e8a-4038-bac7-4e5577274b93"], "metadata": {"page_label": "3", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}}, "cb5ddc8f-dbda-4557-a840-1e320547a0f2": {"node_ids": ["cb87c01d-4e29-4444-a011-1ecf255da0c1", "b041f133-4b99-4c99-94ce-0e06bb59d87e"], "metadata": {"page_label": "4", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}}, "9790f12d-8fbb-451b-8f20-e32e7caaf228": {"node_ids": ["110f2a8a-2548-4cd3-a50e-80062a6b75e8", "561673fa-40e0-4c83-a8fe-f9adee1f64b2"], "metadata": {"page_label": "5", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}}, "d7be831c-9cf8-4ca3-a7b4-1da140047a95": {"node_ids": ["35caf51b-bcbf-4bbd-889e-1992400ffb04", "a76ec774-8dcf-4aee-b0e3-ee93bc0bfbc1"], "metadata": {"page_label": "6", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}}, "916c726b-bbe1-40ca-bcbd-9a997a1eaa24": {"node_ids": ["1371ab67-915e-4824-ba3f-d8a7c1d1f150", "8f61dc97-461e-4bae-9b8f-386c6175fba7", "243f501c-9683-4423-a407-54040b76cf92"], "metadata": {"page_label": "7", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}}, "e4dc0552-1ed3-4566-a1ab-df63dfd74b04": {"node_ids": ["91b29eea-77af-4e13-acfe-8d3acbebb661"], "metadata": {"page_label": "8", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}}, "5e69ed8e-a68c-4097-ac57-173fd1043951": {"node_ids": ["fd216069-f79f-4890-9595-d44086a8b2d5", "3b8e3c46-138f-4bca-851e-b8d03f34f6e0"], "metadata": {"page_label": "9", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}}, "2a32a8f1-3309-4bf4-9559-b165fc1af324": {"node_ids": ["1387d259-896f-46eb-966f-9d214a84f332", "e0a0bc8b-9fdd-4763-9c72-f43301a7aaf7"], "metadata": {"page_label": "10", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}}, "31098157-5ff6-4a52-9c35-320781ea3bd4": {"node_ids": ["b75389bd-45f0-4718-8d9a-9d499650b2de", "d9d4aa39-9b9e-48c5-9141-692b358b22c0"], "metadata": {"page_label": "11", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}}, "40542742-aec1-423e-8af1-02002e279650": {"node_ids": ["5059f07b-53fc-4c41-b737-4e7bc32ea580", "701b18cc-e46a-4173-9dbd-ae51764b94d9"], "metadata": {"page_label": "12", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}}, "43dbd250-fa5f-4d20-89ff-57fb0fddffb5": {"node_ids": ["2ac26ec6-8e2d-4c38-b372-87a3fbaddecb"], "metadata": {"page_label": "13", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}}, "ac1c7c2f-6976-4682-b5ed-b44f89aaa87e": {"node_ids": ["a00703fd-9a48-486a-90ec-27c62200f4a6", "4128dbbd-104d-4975-a7d6-4a645bbd0614"], "metadata": {"page_label": "14", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}}, "4bd10bab-517e-4412-aa4b-1833db2779d7": {"node_ids": ["4c267a67-44fb-4d51-a988-2471b5ec8d26"], "metadata": {"page_label": "15", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}}, "eeb7a7ba-2dbe-4411-b51b-709b06b24fb3": {"node_ids": ["a9bb14cd-c0cf-4a9d-8ba0-150893151cef"], "metadata": {"page_label": "16", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}}, "faa5cfee-2267-4927-9d57-0d993ce6ac9e": {"node_ids": ["75ca7693-3a68-4df5-b37d-bf56c8075bce", "c83fe11c-cf03-4966-911c-ec6d6050ba2b"], "metadata": {"page_label": "17", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}}, "e1206ad4-2875-415d-baa2-213c96ae3fe5": {"node_ids": ["e2f6369c-7916-492c-8d0f-719f67737d65", "ba41b74f-41d8-4e0b-9478-e2ec23c11189"], "metadata": {"page_label": "18", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}}, "0c40234f-5286-4c2c-a086-028a1c41410a": {"node_ids": ["00bab8de-0746-4592-b9c1-7b6f10eb89ac"], "metadata": {"page_label": "19", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}}, "09df8e14-4af3-4ef0-ad85-eddbe3b7a241": {"node_ids": ["075e0013-e8a1-4152-b202-9a6358d40994"], "metadata": {"page_label": "20", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}}, "2b14664e-9550-428b-99f3-1e33ff83ad8d": {"node_ids": ["1e543b19-ce48-4dc2-856e-b98b633dd095"], "metadata": {"page_label": "21", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}}, "c314c64c-400b-4167-9013-34f363ed9e1b": {"node_ids": ["c6ad923d-7c21-4a7d-9087-042f11e03352"], "metadata": {"page_label": "22", "file_name": "2402.12593v2.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2402.12593v2.pdf", "file_type": "application/pdf", "file_size": 1383412, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}}, "40b6fc40-dfdf-4ffd-90ab-f004e35f3c3e": {"node_ids": ["f1c3926c-4533-45ca-bd3d-012f6f72eb96"], "metadata": {"page_label": "1", "file_name": "2405.07354v1.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2405.07354v1.pdf", "file_type": "application/pdf", "file_size": 38960451, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}}, "f2dfa0c2-590f-4686-ae13-dfbf384308b8": {"node_ids": ["fc2a91b9-e628-44a4-9982-c7a65749f6b9"], "metadata": {"page_label": "2", "file_name": "2405.07354v1.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2405.07354v1.pdf", "file_type": "application/pdf", "file_size": 38960451, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}}, "1d2bc51b-a218-49fc-89b5-58121dd07020": {"node_ids": ["1ba63044-7c24-42ba-ac48-c559265dba83"], "metadata": {"page_label": "3", "file_name": "2405.07354v1.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2405.07354v1.pdf", "file_type": "application/pdf", "file_size": 38960451, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}}, "3adc0f79-a995-47df-9ae9-275863354e4c": {"node_ids": ["f1912059-1bf8-4476-a6b6-d695974ead07"], "metadata": {"page_label": "4", "file_name": "2405.07354v1.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2405.07354v1.pdf", "file_type": "application/pdf", "file_size": 38960451, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}}, "b25b349c-450e-4ff7-9976-15274259cc14": {"node_ids": ["5c823c8d-56cf-4fbd-909a-aeafc1ef001b"], "metadata": {"page_label": "5", "file_name": "2405.07354v1.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2405.07354v1.pdf", "file_type": "application/pdf", "file_size": 38960451, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}}, "778cfc29-bfc7-47c1-9a67-7497f4f466ff": {"node_ids": ["67ad840e-5392-463f-8dd8-ad474d9f57b0"], "metadata": {"page_label": "6", "file_name": "2405.07354v1.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2405.07354v1.pdf", "file_type": "application/pdf", "file_size": 38960451, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}}, "b93d8596-9d3a-4fd5-916e-f50a19cdb91b": {"node_ids": ["be52189c-38c8-4808-8359-fdbb5ff22fdd"], "metadata": {"page_label": "7", "file_name": "2405.07354v1.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2405.07354v1.pdf", "file_type": "application/pdf", "file_size": 38960451, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}}, "dd493c2b-26fb-4a4d-b247-07a3e4ac26b5": {"node_ids": ["5cef45c2-56df-434e-95b5-6ac7d0f0497c"], "metadata": {"page_label": "8", "file_name": "2405.07354v1.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2405.07354v1.pdf", "file_type": "application/pdf", "file_size": 38960451, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}}, "8dc1016c-6186-4e3b-9ebc-606da2cecd39": {"node_ids": ["0dacf27b-723a-4298-8bf8-c72744802ff9"], "metadata": {"page_label": "9", "file_name": "2405.07354v1.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2405.07354v1.pdf", "file_type": "application/pdf", "file_size": 38960451, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}}, "edba1f4c-e4fa-4738-ad9a-8ce38c8b4041": {"node_ids": ["e7c52956-4607-4f28-ac70-101228ae4b0e"], "metadata": {"page_label": "10", "file_name": "2405.07354v1.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2405.07354v1.pdf", "file_type": "application/pdf", "file_size": 38960451, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}}, "a03af834-8fe0-401b-8811-ec6904c76f48": {"node_ids": ["990b7974-e3b2-4a42-b580-37a730741fb6", "e7b22d09-08d1-46fe-96cd-14700b5b8bf9"], "metadata": {"page_label": "11", "file_name": "2405.07354v1.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2405.07354v1.pdf", "file_type": "application/pdf", "file_size": 38960451, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}}, "cf1c79c5-9a9f-47bb-976c-e6ff6f523638": {"node_ids": ["21238e9f-fda8-4388-8e2d-f5bdae7eab76", "d7769b81-6b5d-4ca3-9ed9-6ae5672df044"], "metadata": {"page_label": "12", "file_name": "2405.07354v1.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2405.07354v1.pdf", "file_type": "application/pdf", "file_size": 38960451, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}}, "6b404874-c543-4846-8fd8-ced63d78166a": {"node_ids": ["fdcf0c5b-cf41-451f-87f2-502da726e58e"], "metadata": {"page_label": "13", "file_name": "2405.07354v1.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2405.07354v1.pdf", "file_type": "application/pdf", "file_size": 38960451, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}}, "1c0ade49-d780-4ac7-b99b-48480f85a7ef": {"node_ids": ["60320fb0-420a-4b86-a7c8-6ae1b7409b2f"], "metadata": {"page_label": "14", "file_name": "2405.07354v1.pdf", "file_path": "/Users/michael/Documents/GitHub/chatbot-hdir-test/data/2405.07354v1.pdf", "file_type": "application/pdf", "file_size": 38960451, "creation_date": "2025-04-03", "last_modified_date": "2025-04-01"}}}}